{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    \"\"\"Base class for backbone networks. Handles freezing layers etc.\n",
    "    args:\n",
    "        frozen_layers  -  Name of layers to freeze. Either list of strings, 'none' or 'all'. Default: 'none'.\n",
    "    \"\"\"\n",
    "    def __init__(self, frozen_layers=()):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(frozen_layers, str):\n",
    "            if frozen_layers.lower() == 'none':\n",
    "                frozen_layers = ()\n",
    "            elif frozen_layers.lower() != 'all':\n",
    "                raise ValueError('Unknown option for frozen layers: \\\"{}\\\". Should be \\\"all\\\", \\\"none\\\" or list of layer names.'.format(frozen_layers))\n",
    "\n",
    "        self.frozen_layers = frozen_layers\n",
    "        self._is_frozen_nograd = False\n",
    "\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        if mode == True:\n",
    "            self._set_frozen_to_eval()\n",
    "        if not self._is_frozen_nograd:\n",
    "            self._set_frozen_to_nograd()\n",
    "            self._is_frozen_nograd = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _set_frozen_to_eval(self):\n",
    "        if isinstance(self.frozen_layers, str) and self.frozen_layers.lower() == 'all':\n",
    "            self.eval()\n",
    "        else:\n",
    "            for layer in self.frozen_layers:\n",
    "                getattr(self, layer).eval()\n",
    "\n",
    "\n",
    "    def _set_frozen_to_nograd(self):\n",
    "        if isinstance(self.frozen_layers, str) and self.frozen_layers.lower() == 'all':\n",
    "            for p in self.parameters():\n",
    "                p.requires_grad_(False)\n",
    "        else:\n",
    "            for layer in self.frozen_layers:\n",
    "                for p in getattr(self, layer).parameters():\n",
    "                    p.requires_grad_(False)\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class channel_selection(nn.Module):\n",
    "    \"\"\"\n",
    "    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n",
    "    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels):\n",
    "        \"\"\"\n",
    "        Initialize the `indexes` with all one vector with the length same as the number of channels.\n",
    "        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n",
    "        \"\"\"\n",
    "        super(channel_selection, self).__init__()\n",
    "        self.indexes = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "        ---------\n",
    "        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n",
    "        \"\"\"\n",
    "        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n",
    "        if selected_index.size == 1:\n",
    "            selected_index = np.resize(selected_index, (1,)) \n",
    "        output = input_tensor[:, :, :, :]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "# from .base import Backbone\n",
    "# from .channel_selection import channel_selection\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, use_bn=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.select = channel_selection(planes*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         out = self.select(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(Backbone):\n",
    "    \"\"\" ResNet network module. Allows extracting specific feature blocks.\"\"\"\n",
    "    def __init__(self, block, layers, output_layers, num_classes=1000, inplanes=64, dilation_factor=1, frozen_layers=()):\n",
    "        self.inplanes = inplanes\n",
    "        super(ResNet, self).__init__(frozen_layers=frozen_layers)\n",
    "        self.output_layers = output_layers\n",
    "        self.conv1 = nn.Conv2d(3, inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]\n",
    "        self.layer1 = self._make_layer(block, inplanes, layers[0], dilation=max(dilation_factor//8, 1))\n",
    "        self.layer2 = self._make_layer(block, inplanes*2, layers[1], stride=stride[0], dilation=max(dilation_factor//4, 1))\n",
    "        self.layer3 = self._make_layer(block, inplanes*4, layers[2], stride=stride[1], dilation=max(dilation_factor//2, 1))\n",
    "        self.layer4 = self._make_layer(block, inplanes*8, layers[3], stride=stride[2], dilation=dilation_factor)\n",
    "\n",
    "        out_feature_strides = {'conv1': 4, 'layer1': 4, 'layer2': 4*stride[0], 'layer3': 4*stride[0]*stride[1],\n",
    "                               'layer4': 4*stride[0]*stride[1]*stride[2]}\n",
    "\n",
    "        # TODO better way?\n",
    "        if isinstance(self.layer1[0], BasicBlock):\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': inplanes, 'layer2': inplanes*2, 'layer3': inplanes*4,\n",
    "                               'layer4': inplanes*8}\n",
    "        elif isinstance(self.layer1[0], Bottleneck):\n",
    "            base_num_channels = 4 * inplanes\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': base_num_channels, 'layer2': base_num_channels * 2,\n",
    "                                    'layer3': base_num_channels * 4, 'layer4': base_num_channels * 8}\n",
    "        else:\n",
    "            raise Exception('block not supported')\n",
    "\n",
    "        self._out_feature_strides = out_feature_strides\n",
    "        self._out_feature_channels = out_feature_channels\n",
    "\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(inplanes*8 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def out_feature_strides(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_strides\n",
    "        else:\n",
    "            return self._out_feature_strides[layer]\n",
    "\n",
    "    def out_feature_channels(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_channels\n",
    "        else:\n",
    "            return self._out_feature_channels[layer]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                channel_selection(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, dilation=dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _add_output_and_check(self, name, x, outputs, output_layers):\n",
    "        if name in output_layers:\n",
    "            outputs[name] = x\n",
    "        return len(output_layers) == len(outputs)\n",
    "\n",
    "    def forward(self, x, output_layers=None):\n",
    "        \"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"\n",
    "        outputs = OrderedDict()\n",
    "\n",
    "        if output_layers is None:\n",
    "            output_layers = self.output_layers\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) ####### select daal dena\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self._add_output_and_check('conv1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        if self._add_output_and_check('layer1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        if self._add_output_and_check('layer2', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        if self._add_output_and_check('layer3', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self._add_output_and_check('layer4', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._add_output_and_check('fc', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        if len(output_layers) == 1 and output_layers[0] == 'default':\n",
    "            return x\n",
    "\n",
    "        raise ValueError('output_layer is wrong.')\n",
    "\n",
    "\n",
    "def resnet_baby(output_layers=None, pretrained=False, inplanes=16, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, inplanes=inplanes, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], progress = False), strict = False )\n",
    "    return model\n",
    "\n",
    "def resnet101(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck,[3, 4, 23, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/pytracking\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/pytracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.admin.loading import torch_load_legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['layer1.0.select.indexes', 'layer1.0.downsample.2.indexes', 'layer1.1.select.indexes', 'layer1.2.select.indexes', 'layer2.0.select.indexes', 'layer2.0.downsample.2.indexes', 'layer2.1.select.indexes', 'layer2.2.select.indexes', 'layer2.3.select.indexes', 'layer3.0.select.indexes', 'layer3.0.downsample.2.indexes', 'layer3.1.select.indexes', 'layer3.2.select.indexes', 'layer3.3.select.indexes', 'layer3.4.select.indexes', 'layer3.5.select.indexes', 'layer4.0.select.indexes', 'layer4.0.downsample.2.indexes', 'layer4.1.select.indexes', 'layer4.2.select.indexes'], unexpected_keys=['initializer.filter_conv.weight', 'initializer.filter_conv.bias', 'optimizer.log_step_length', 'optimizer.filter_reg', 'optimizer.label_map_predictor.weight', 'optimizer.target_mask_predictor.0.weight', 'optimizer.spatial_weight_predictor.weight', '_extractor.0.weight', '_1r.0.weight', '_1r.0.bias', '_1r.1.weight', '_1r.1.bias', '_1r.1.running_mean', '_1r.1.running_var', '_1r.1.num_batches_tracked', '_1t.0.weight', '_1t.0.bias', '_1t.1.weight', '_1t.1.bias', '_1t.1.running_mean', '_1t.1.running_var', '_1t.1.num_batches_tracked', '_2t.0.weight', '_2t.0.bias', '_2t.1.weight', '_2t.1.bias', '_2t.1.running_mean', '_2t.1.running_var', '_2t.1.num_batches_tracked', 'r.0.weight', 'r.0.bias', 'r.1.weight', 'r.1.bias', 'r.1.running_mean', 'r.1.running_var', 'r.1.num_batches_tracked', '3r.0.weight', '3r.0.bias', '3r.1.weight', '3r.1.bias', '3r.1.running_mean', '3r.1.running_var', '3r.1.num_batches_tracked', '4r.0.weight', '4r.0.bias', '4r.1.weight', '4r.1.bias', '4r.1.running_mean', '4r.1.running_var', '4r.1.num_batches_tracked', 't.linear.weight', 't.linear.bias', 't.bn.weight', 't.bn.bias', 't.bn.running_mean', 't.bn.running_var', 't.bn.num_batches_tracked', 'redictor.weight', 'redictor.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch_load_legacy('/workspace/tracking_datasets/saved_ckpts/ltr/dimp/sparse-pretrained/dimp50/DiMPnet_ep0050.pth.tar')['net']\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state = OrderedDict()\n",
    "\n",
    "for key, value in ckpt.items():\n",
    "    key = key[18:] # remove `module.`\n",
    "    new_state[key] = value\n",
    "model.load_state_dict(new_state, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "^^^^\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([256])\n",
      "^^^^\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([256])\n",
      "$$$$$$$$$$$$$\n",
      "^^^^\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "^^^^\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512])\n",
      "^^^^\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512])\n",
      "^^^^\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([512])\n",
      "$$$$$$$$$$$$$\n",
      "^^^^\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024])\n",
      "torch.Size([1024])\n",
      "^^^^\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024])\n",
      "^^^^\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024])\n",
      "^^^^\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024])\n",
      "^^^^\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024])\n",
      "^^^^\n",
      "torch.Size([256])\n",
      "torch.Size([256])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "count1=0\n",
    "count2=0\n",
    "LL1=[]\n",
    "LL2=[]\n",
    "LL3=[]\n",
    "bt=[]\n",
    "for idx, m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if idx.split('.')[0] == 'layer1':\n",
    "            x = int(idx[7])\n",
    "            if x==0 and count1<4:\n",
    "                count1 +=1\n",
    "                bt.append(m.weight.data.abs().clone())\n",
    "            if x==0 and count1==4:\n",
    "                LL1.append(bt)\n",
    "                bt = []\n",
    "                count1=0\n",
    "            if x!=0 and count2<3:\n",
    "                count2 +=1\n",
    "                bt.append(m.weight.data.abs().clone())\n",
    "            if x!=0 and count2==3:\n",
    "                LL1.append(bt)\n",
    "                bt=[]\n",
    "                count2=0\n",
    "        if idx.split('.')[0] == 'layer2':\n",
    "            x = int(idx[7])\n",
    "            if x==0 and count1<4:\n",
    "                count1 +=1\n",
    "                bt.append(m.weight.data.abs().clone())\n",
    "            if x==0 and count1==4:\n",
    "                LL2.append(bt)\n",
    "                bt = []\n",
    "                count1=0\n",
    "            if x!=0 and count2<3:\n",
    "                count2 +=1\n",
    "                bt.append(m.weight.data.abs().clone())\n",
    "            if x!=0 and count2==3:\n",
    "                LL2.append(bt)\n",
    "                bt=[]\n",
    "                count2=0\n",
    "        if idx.split('.')[0] == 'layer3':\n",
    "            x = int(idx[7])\n",
    "            if x==0 and count1<4:\n",
    "                count1 +=1\n",
    "                bt.append(m.weight.data.abs().clone())\n",
    "            if x==0 and count1==4:\n",
    "                LL3.append(bt)\n",
    "                bt = []\n",
    "                count1=0\n",
    "            if x!=0 and count2<3:\n",
    "                count2 +=1\n",
    "                bt.append(m.weight.data.abs().clone())\n",
    "            if x!=0 and count2==3:\n",
    "                LL3.append(bt)\n",
    "                bt=[]\n",
    "                count2=0\n",
    "\n",
    "# print(bt)\n",
    "for i in LL1:\n",
    "    print(\"^^^^\")\n",
    "    for j in i:\n",
    "        print(j.shape)\n",
    "print(\"$$$$$$$$$$$$$\")\n",
    "for i in LL2:\n",
    "    print(\"^^^^\")\n",
    "    for j in i:\n",
    "        print(j.shape)\n",
    "print(\"$$$$$$$$$$$$$\")\n",
    "for i in LL3:\n",
    "    print(\"^^^^\")\n",
    "    for j in i:\n",
    "        print(j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^^^^\n",
      "torch.Size([640])\n",
      "^^^^\n",
      "torch.Size([384])\n",
      "^^^^\n",
      "torch.Size([384])\n",
      "$$$$$$$$$$$$$\n",
      "^^^^\n",
      "torch.Size([1280])\n",
      "^^^^\n",
      "torch.Size([768])\n",
      "^^^^\n",
      "torch.Size([768])\n",
      "^^^^\n",
      "torch.Size([768])\n",
      "$$$$$$$$$$$$$\n",
      "^^^^\n",
      "torch.Size([2560])\n",
      "^^^^\n",
      "torch.Size([1536])\n",
      "^^^^\n",
      "torch.Size([1536])\n",
      "^^^^\n",
      "torch.Size([1536])\n",
      "^^^^\n",
      "torch.Size([1536])\n",
      "^^^^\n",
      "torch.Size([1536])\n"
     ]
    }
   ],
   "source": [
    "megalist = []\n",
    "for i in LL1:\n",
    "    print(\"^^^^\")\n",
    "    jj = None\n",
    "    for j in i:\n",
    "        if jj is None:\n",
    "            jj = j\n",
    "        else:\n",
    "            jj = torch.cat((jj, j), 0)\n",
    "    print(jj.shape)\n",
    "    megalist.append(jj)\n",
    "print(\"$$$$$$$$$$$$$\")\n",
    "for i in LL2:\n",
    "    print(\"^^^^\")\n",
    "    jj = None\n",
    "    for j in i:\n",
    "        if jj is None:\n",
    "            jj = j\n",
    "        else:\n",
    "            jj = torch.cat((jj, j), 0)\n",
    "    print(jj.shape)\n",
    "    megalist.append(jj)\n",
    "print(\"$$$$$$$$$$$$$\")\n",
    "for i in LL3:\n",
    "    print(\"^^^^\")\n",
    "    jj = None\n",
    "    for j in i:\n",
    "        if jj is None:\n",
    "            jj = j\n",
    "        else:\n",
    "            jj = torch.cat((jj, j), 0)\n",
    "    print(jj.shape)\n",
    "    megalist.append(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15232\n"
     ]
    }
   ],
   "source": [
    "total=0\n",
    "for i in megalist:\n",
    "    total+=len(i)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0944)\n",
      "tensor(0.0467)\n",
      "tensor(0.0082)\n",
      "tensor(0.0559)\n",
      "tensor(0.0143)\n",
      "tensor(0.0785)\n",
      "tensor(0.0533)\n",
      "tensor(0.0857)\n",
      "tensor(0.0835)\n",
      "tensor(0.0718)\n",
      "tensor(0.0703)\n",
      "tensor(0.0716)\n",
      "tensor(0.0880)\n"
     ]
    }
   ],
   "source": [
    "thre_list = []\n",
    "for bn in megalist:\n",
    "    y, i = torch.sort(bn)\n",
    "    thre_index = int(len(bn) * 0.25)\n",
    "    thre = y[thre_index]\n",
    "    print(thre)\n",
    "    thre_list.append(thre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_bn_count = 3\n",
    "layer2_bn_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64.)\n",
      "layer index: 2 \t total channel: 64 \t remaining channel: 64\n",
      "tensor(58.)\n",
      "layer index: 8 \t total channel: 64 \t remaining channel: 58\n",
      "tensor(60.)\n",
      "layer index: 10 \t total channel: 64 \t remaining channel: 60\n",
      "tensor(151.)\n",
      "layer index: 12 \t total channel: 256 \t remaining channel: 151\n",
      "yes\n",
      "tensor(210.) **\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 210\n",
      "tensor(60.)\n",
      "layer index: 21 \t total channel: 64 \t remaining channel: 60\n",
      "tensor(64.)\n",
      "layer index: 23 \t total channel: 64 \t remaining channel: 64\n",
      "tensor(163.)\n",
      "layer index: 25 \t total channel: 256 \t remaining channel: 163\n",
      "tensor(64.)\n",
      "layer index: 30 \t total channel: 64 \t remaining channel: 64\n",
      "tensor(64.)\n",
      "layer index: 32 \t total channel: 64 \t remaining channel: 64\n",
      "tensor(159.)\n",
      "layer index: 34 \t total channel: 256 \t remaining channel: 159\n",
      "tensor(128.)\n",
      "layer index: 40 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(128.)\n",
      "layer index: 42 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(324.)\n",
      "layer index: 44 \t total channel: 512 \t remaining channel: 324\n",
      "yes\n",
      "tensor(379.) **\n",
      "layer index: 49 \t total channel: 512 \t remaining channel: 379\n",
      "tensor(128.)\n",
      "layer index: 53 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(128.)\n",
      "layer index: 55 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(319.)\n",
      "layer index: 57 \t total channel: 512 \t remaining channel: 319\n",
      "tensor(128.)\n",
      "layer index: 62 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(128.)\n",
      "layer index: 64 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(319.)\n",
      "layer index: 66 \t total channel: 512 \t remaining channel: 319\n",
      "tensor(128.)\n",
      "layer index: 71 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(128.)\n",
      "layer index: 73 \t total channel: 128 \t remaining channel: 128\n",
      "tensor(319.)\n",
      "layer index: 75 \t total channel: 512 \t remaining channel: 319\n",
      "tensor(256.)\n",
      "layer index: 81 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(256.)\n",
      "layer index: 83 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(978.)\n",
      "layer index: 85 \t total channel: 1024 \t remaining channel: 978\n",
      "yes\n",
      "tensor(981.) **\n",
      "layer index: 90 \t total channel: 1024 \t remaining channel: 981\n",
      "tensor(256.)\n",
      "layer index: 94 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(256.)\n",
      "layer index: 96 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(708.)\n",
      "layer index: 98 \t total channel: 1024 \t remaining channel: 708\n",
      "tensor(256.)\n",
      "layer index: 103 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(256.)\n",
      "layer index: 105 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(824.)\n",
      "layer index: 107 \t total channel: 1024 \t remaining channel: 824\n",
      "tensor(256.)\n",
      "layer index: 112 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(256.)\n",
      "layer index: 114 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(521.)\n",
      "layer index: 116 \t total channel: 1024 \t remaining channel: 521\n",
      "tensor(256.)\n",
      "layer index: 121 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(256.)\n",
      "layer index: 123 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(552.)\n",
      "layer index: 125 \t total channel: 1024 \t remaining channel: 552\n",
      "tensor(256.)\n",
      "layer index: 130 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(256.)\n",
      "layer index: 132 \t total channel: 256 \t remaining channel: 256\n",
      "tensor(819.)\n",
      "layer index: 134 \t total channel: 1024 \t remaining channel: 819\n",
      "tensor(512.)\n",
      "layer index: 140 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(512.)\n",
      "layer index: 142 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(2048.)\n",
      "layer index: 144 \t total channel: 2048 \t remaining channel: 2048\n",
      "yes\n",
      "tensor(2048.) **\n",
      "layer index: 149 \t total channel: 2048 \t remaining channel: 2048\n",
      "tensor(512.)\n",
      "layer index: 153 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(512.)\n",
      "layer index: 155 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(2048.)\n",
      "layer index: 157 \t total channel: 2048 \t remaining channel: 2048\n",
      "tensor(512.)\n",
      "layer index: 162 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(512.)\n",
      "layer index: 164 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(2048.)\n",
      "layer index: 166 \t total channel: 2048 \t remaining channel: 2048\n",
      "tensor(0.1996)\n"
     ]
    }
   ],
   "source": [
    "pruned = 0\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "modules = list(model.named_modules())\n",
    "for k, (idx, m) in enumerate(modules):\n",
    "#     print(idx)\n",
    "    if isinstance(m, nn.BatchNorm2d) :\n",
    "        if idx.split('.')[0] == 'layer1' or idx.split('.')[0] == 'layer2' or idx.split('.')[0] == 'layer3':\n",
    "            x = int(idx[5])\n",
    "            y = int(idx[7])\n",
    "            if x==1:\n",
    "                thre = thre_list[y]\n",
    "            elif x==2:\n",
    "                thre = thre_list[layer1_bn_count + y]\n",
    "            elif x==3:\n",
    "                thre = thre_list[layer2_bn_count + y]\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            mask = weight_copy.gt(thre).float()\n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "#             if not isinstance(modules[k-2],nn.Sequential):\n",
    "#             print(idx.split('.')[1])\n",
    "            if not idx.split('.')[2]=='downsample':\n",
    "                cfg.append(int(torch.sum(mask)))\n",
    "                print(torch.sum(mask))\n",
    "            else:\n",
    "                print('yes')\n",
    "                print(torch.sum(mask),'**')\n",
    "    #             print(modules[k-2])\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))            \n",
    "        else:\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            mask = weight_copy.gt(0.0).float()\n",
    "#             pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "            try:\n",
    "                if not idx.split('.')[2]=='downsample':\n",
    "                    cfg.append(int(torch.sum(mask)))\n",
    "                    print(torch.sum(mask))\n",
    "                else:\n",
    "                    print('yes')\n",
    "                    print(torch.sum(mask),'**')\n",
    "            except:\n",
    "                cfg.append(int(torch.sum(mask)))\n",
    "                print(torch.sum(mask))\n",
    "    #             print(modules[k-2])\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "    elif isinstance(m, nn.MaxPool2d):\n",
    "        cfg.append('M')\n",
    "\n",
    "pruned_ratio = pruned/(total)\n",
    "print(pruned_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layer index: 2 \t total channel: 64 \t remaining channel: 62\n",
    "layer index: 9 \t total channel: 64 \t remaining channel: 49\n",
    "layer index: 11 \t total channel: 64 \t remaining channel: 53\n",
    "layer index: 13 \t total channel: 256 \t remaining channel: 131\n",
    "layer index: 17 \t total channel: 256 \t remaining channel: 198\n",
    "layer index: 21 \t total channel: 64 \t remaining channel: 56\n",
    "layer index: 23 \t total channel: 64 \t remaining channel: 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 'M',\n",
       " 58,\n",
       " 60,\n",
       " 151,\n",
       " 60,\n",
       " 64,\n",
       " 163,\n",
       " 64,\n",
       " 64,\n",
       " 159,\n",
       " 128,\n",
       " 128,\n",
       " 324,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 256,\n",
       " 256,\n",
       " 978,\n",
       " 256,\n",
       " 256,\n",
       " 708,\n",
       " 256,\n",
       " 256,\n",
       " 824,\n",
       " 256,\n",
       " 256,\n",
       " 521,\n",
       " 256,\n",
       " 256,\n",
       " 552,\n",
       " 256,\n",
       " 256,\n",
       " 819,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "# from .base import Backbone\n",
    "# from .channel_selection import channel_selection\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, use_bn=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None, dilation=1,):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes,cfg[1], kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg[1])\n",
    "        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n",
    "                               padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg[2])\n",
    "        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.select = channel_selection(planes*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         out = self.select(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(Backbone):\n",
    "    \"\"\" ResNet network module. Allows extracting specific feature blocks.\"\"\"\n",
    "    def __init__(self, block, layers, output_layers,cfg = None , num_classes=1000, inplanes=64, dilation_factor=1, frozen_layers=()):\n",
    "        self.inplanes = inplanes\n",
    "        super(ResNet, self).__init__(frozen_layers=frozen_layers)\n",
    "        self.output_layers = output_layers\n",
    "        self.conv1 = nn.Conv2d(3, inplanes , kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]\n",
    "        self.layer1 = self._make_layer(block, inplanes, layers[0], dilation=max(dilation_factor//8, 1), cfg = cfg[0:3*layers[0]])\n",
    "        self.layer2 = self._make_layer(block, inplanes*2, layers[1], stride=stride[0], dilation=max(dilation_factor//4, 1), cfg = cfg[3*layers[0]:3*layers[1]+3*layers[0]])\n",
    "        self.layer3 = self._make_layer(block, inplanes*4, layers[2], stride=stride[1], dilation=max(dilation_factor//2, 1), cfg = cfg[3*layers[1]+3*layers[0]:3*layers[1]+3*layers[0]+3*layers[2]])\n",
    "        self.layer4 = self._make_layer(block, inplanes*8, layers[3], stride=stride[2], dilation=dilation_factor, cfg = cfg[3*layers[1]+3*layers[0]+3*layers[2]:3*layers[1]+3*layers[0]+3*layers[2]+3*layers[3]])\n",
    "\n",
    "        out_feature_strides = {'conv1': 4, 'layer1': 4, 'layer2': 4*stride[0], 'layer3': 4*stride[0]*stride[1],\n",
    "                               'layer4': 4*stride[0]*stride[1]*stride[2]}\n",
    "\n",
    "        # TODO better way?\n",
    "        if isinstance(self.layer1[0], BasicBlock):\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': inplanes, 'layer2': inplanes*2, 'layer3': inplanes*4,\n",
    "                               'layer4': inplanes*8}\n",
    "        elif isinstance(self.layer1[0], Bottleneck):\n",
    "            base_num_channels = 4 * inplanes\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': base_num_channels, 'layer2': base_num_channels * 2,\n",
    "                                    'layer3': base_num_channels * 4, 'layer4': base_num_channels * 8}\n",
    "        else:\n",
    "            raise Exception('block not supported')\n",
    "\n",
    "        self._out_feature_strides = out_feature_strides\n",
    "        self._out_feature_channels = out_feature_channels\n",
    "\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(cfg[-1], num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def out_feature_strides(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_strides\n",
    "        else:\n",
    "            return self._out_feature_strides[layer]\n",
    "\n",
    "    def out_feature_channels(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_channels\n",
    "        else:\n",
    "            return self._out_feature_channels[layer]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, cfg=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                channel_selection(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, cfg[0:3], stride, downsample, dilation=dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, cfg[3*i:3*(i+1)]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _add_output_and_check(self, name, x, outputs, output_layers):\n",
    "        if name in output_layers:\n",
    "            outputs[name] = x\n",
    "        return len(output_layers) == len(outputs)\n",
    "\n",
    "    def forward(self, x, output_layers=None):\n",
    "        \"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"\n",
    "        outputs = OrderedDict()\n",
    "\n",
    "        if output_layers is None:\n",
    "            output_layers = self.output_layers\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) ####### select daal dena\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self._add_output_and_check('conv1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        if self._add_output_and_check('layer1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        if self._add_output_and_check('layer2', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        if self._add_output_and_check('layer3', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self._add_output_and_check('layer4', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._add_output_and_check('fc', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        if len(output_layers) == 1 and output_layers[0] == 'default':\n",
    "            return x\n",
    "\n",
    "        raise ValueError('output_layer is wrong.')\n",
    "\n",
    "\n",
    "def resnet_baby(output_layers=None, pretrained=False, inplanes=16, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, inplanes=inplanes, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(output_layers=None, pretrained=False,cfg = None,**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3],output_layers,cfg=cfg,**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], progress = False), strict = False )\n",
    "    return model\n",
    "\n",
    "def resnet101(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck,[3, 4, 23, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 58,\n",
       " 60,\n",
       " 151,\n",
       " 60,\n",
       " 64,\n",
       " 163,\n",
       " 64,\n",
       " 64,\n",
       " 159,\n",
       " 128,\n",
       " 128,\n",
       " 324,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 256,\n",
       " 256,\n",
       " 978,\n",
       " 256,\n",
       " 256,\n",
       " 708,\n",
       " 256,\n",
       " 256,\n",
       " 824,\n",
       " 256,\n",
       " 256,\n",
       " 521,\n",
       " 256,\n",
       " 256,\n",
       " 552,\n",
       " 256,\n",
       " 256,\n",
       " 819,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = resnet50(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(58, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(60, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAHAR ka conv torch.Size([64, 3, 7, 7])\n",
      "CASE 1  torch.Size([58, 64, 1, 1])\n",
      "CASE 2  torch.Size([60, 58, 3, 3])\n",
      "CASE 3  torch.Size([256, 60, 1, 1])\n",
      "DOWN ka conv torch.Size([256, 64, 1, 1])\n",
      "CASE 1  torch.Size([60, 256, 1, 1])\n",
      "CASE 2  torch.Size([64, 60, 3, 3])\n",
      "CASE 3  torch.Size([256, 64, 1, 1])\n",
      "CASE 1  torch.Size([64, 256, 1, 1])\n",
      "CASE 2  torch.Size([64, 64, 3, 3])\n",
      "CASE 3  torch.Size([256, 64, 1, 1])\n",
      "CASE 1  torch.Size([128, 256, 1, 1])\n",
      "CASE 2  torch.Size([128, 128, 3, 3])\n",
      "CASE 3  torch.Size([512, 128, 1, 1])\n",
      "DOWN ka conv torch.Size([512, 256, 1, 1])\n",
      "CASE 1  torch.Size([128, 512, 1, 1])\n",
      "CASE 2  torch.Size([128, 128, 3, 3])\n",
      "CASE 3  torch.Size([512, 128, 1, 1])\n",
      "CASE 1  torch.Size([128, 512, 1, 1])\n",
      "CASE 2  torch.Size([128, 128, 3, 3])\n",
      "CASE 3  torch.Size([512, 128, 1, 1])\n",
      "CASE 1  torch.Size([128, 512, 1, 1])\n",
      "CASE 2  torch.Size([128, 128, 3, 3])\n",
      "CASE 3  torch.Size([512, 128, 1, 1])\n",
      "CASE 1  torch.Size([256, 512, 1, 1])\n",
      "CASE 2  torch.Size([256, 256, 3, 3])\n",
      "CASE 3  torch.Size([1024, 256, 1, 1])\n",
      "DOWN ka conv torch.Size([1024, 512, 1, 1])\n",
      "CASE 1  torch.Size([256, 1024, 1, 1])\n",
      "CASE 2  torch.Size([256, 256, 3, 3])\n",
      "CASE 3  torch.Size([1024, 256, 1, 1])\n",
      "CASE 1  torch.Size([256, 1024, 1, 1])\n",
      "CASE 2  torch.Size([256, 256, 3, 3])\n",
      "CASE 3  torch.Size([1024, 256, 1, 1])\n",
      "CASE 1  torch.Size([256, 1024, 1, 1])\n",
      "CASE 2  torch.Size([256, 256, 3, 3])\n",
      "CASE 3  torch.Size([1024, 256, 1, 1])\n",
      "CASE 1  torch.Size([256, 1024, 1, 1])\n",
      "CASE 2  torch.Size([256, 256, 3, 3])\n",
      "CASE 3  torch.Size([1024, 256, 1, 1])\n",
      "CASE 1  torch.Size([256, 1024, 1, 1])\n",
      "CASE 2  torch.Size([256, 256, 3, 3])\n",
      "CASE 3  torch.Size([1024, 256, 1, 1])\n",
      "CASE 1  torch.Size([512, 1024, 1, 1])\n",
      "CASE 2  torch.Size([512, 512, 3, 3])\n",
      "CASE 3  torch.Size([2048, 512, 1, 1])\n",
      "DOWN ka conv torch.Size([2048, 1024, 1, 1])\n",
      "CASE 1  torch.Size([512, 2048, 1, 1])\n",
      "CASE 2  torch.Size([512, 512, 3, 3])\n",
      "CASE 3  torch.Size([2048, 512, 1, 1])\n",
      "CASE 1  torch.Size([512, 2048, 1, 1])\n",
      "CASE 2  torch.Size([512, 512, 3, 3])\n",
      "CASE 3  torch.Size([2048, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "newmodel = resnet50(cfg=cfg)\n",
    "old_modules = list(model.modules())\n",
    "new_modules = list(newmodel.modules())\n",
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "conv_count = 0\n",
    "first_bn = False\n",
    "\n",
    "for layer_id in range(len(old_modules)):\n",
    "    m0 = old_modules[layer_id]\n",
    "    m1 = new_modules[layer_id]\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        if first_bn==False:\n",
    "            first_bn=True\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "            continue\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "        if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "            # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "\n",
    "            # We need to set the channel selection layer.\n",
    "            m2 = new_modules[layer_id + 1]\n",
    "            m2.indexes.data.zero_()\n",
    "            m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        else:\n",
    "            m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "            m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "            m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "            m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "    \n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        if conv_count == 0:\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            conv_count += 1\n",
    "            print(\"BAHAR ka conv\", m1.weight.data.shape)\n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+2], nn.Conv2d) and not isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "            # Residual first case\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            w1 = m0.weight.data[idx1.tolist(), :, :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            print(\"CASE 1 \", m1.weight.data.shape)\n",
    "#             if conv_count % 3 != 1:           \n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+2], nn.Conv2d) and isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "            # Residual second case\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            print(\"CASE 2 \", m1.weight.data.shape)\n",
    "#             if conv_count % 3 != 1:           \n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+3], nn.ReLU) and isinstance(old_modules[layer_id+2], channel_selection):\n",
    "            # Residual third case\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            print(\"CASE 3 \", m1.weight.data.shape)\n",
    "            continue\n",
    "        m1.weight.data = m0.weight.data.clone()\n",
    "        print(\"DOWN ka conv\", m1.weight.data.shape)\n",
    " \n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        if idx0.size == 1:\n",
    "            idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "        m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "        m1.bias.data = m0.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# newmodel = resnet101(cfg=cfg)\n",
    "# old_modules = list(model.modules())\n",
    "# new_modules = list(newmodel.modules())\n",
    "# layer_id_in_cfg = 0\n",
    "# start_mask = torch.ones(3)\n",
    "# end_mask = cfg_mask[layer_id_in_cfg]\n",
    "# conv_count = 0\n",
    "# first_bn = False\n",
    "\n",
    "# for layer_id in range(len(old_modules)):\n",
    "#     m0 = old_modules[layer_id]\n",
    "#     m1 = new_modules[layer_id]\n",
    "#     if isinstance(m0, nn.BatchNorm2d):\n",
    "#         if first_bn==False:\n",
    "#             first_bn=True\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             m1.bias.data = m0.bias.data.clone()\n",
    "#             m1.running_mean = m0.running_mean.clone()\n",
    "#             m1.running_var = m0.running_var.clone()\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "#             continue\n",
    "#         idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#         if idx1.size == 1:\n",
    "#             idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "#         if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "#             # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             m1.bias.data = m0.bias.data.clone()\n",
    "#             m1.running_mean = m0.running_mean.clone()\n",
    "#             m1.running_var = m0.running_var.clone()\n",
    "\n",
    "#             # We need to set the channel selection layer.\n",
    "#             m2 = new_modules[layer_id + 1]\n",
    "#             m2.indexes.data.zero_()\n",
    "#             m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "#         else:\n",
    "#             m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "#             m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "#             m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "#             m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "    \n",
    "#     elif isinstance(m0, nn.Conv2d):\n",
    "#         if conv_count == 0:\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             conv_count += 1\n",
    "#             print(\"BAHAR ka conv\", m1.weight.data.shape)\n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id+2], nn.Conv2d) and not isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "#             # Residual first case\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "# #             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "# #             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "#             w1 = m0.weight.data[idx1.tolist(), :, :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             print(\"CASE 1 \", m1.weight.data.shape)\n",
    "# #             if conv_count % 3 != 1:           \n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id+2], nn.Conv2d) and isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "#             # Residual second case\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "# #             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "#             w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             print(\"CASE 2 \", m1.weight.data.shape)\n",
    "# #             if conv_count % 3 != 1:           \n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id+3], nn.ReLU) and isinstance(old_modules[layer_id+2], channel_selection):\n",
    "#             # Residual third case\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "# #             print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             print(\"CASE 3 \", m1.weight.data.shape)\n",
    "#             continue\n",
    "#         m1.weight.data = m0.weight.data.clone()\n",
    "#         print(\"DOWN ka conv\", m1.weight.data.shape)\n",
    " \n",
    "#     elif isinstance(m0, nn.Linear):\n",
    "#         idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#         if idx0.size == 1:\n",
    "#             idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "#         m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "#         m1.bias.data = m0.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()},'/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_50p.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()},'/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/BN_layerwise_pruned_75p.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.load_state_dict(torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/BN_layerwise_pruned_75p.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_75p.pth.tar')['state_dict']['layer1.1.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_75p.pth.tar')['state_dict']['layer1.1.conv2.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_75p.pth.tar')['state_dict']['layer1.1.conv3.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg1 = torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/BN_layerwise_pruned_75p.pth.tar')['cfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 58,\n",
       " 60,\n",
       " 151,\n",
       " 60,\n",
       " 64,\n",
       " 163,\n",
       " 64,\n",
       " 64,\n",
       " 159,\n",
       " 128,\n",
       " 128,\n",
       " 324,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 256,\n",
       " 256,\n",
       " 978,\n",
       " 256,\n",
       " 256,\n",
       " 708,\n",
       " 256,\n",
       " 256,\n",
       " 824,\n",
       " 256,\n",
       " 256,\n",
       " 521,\n",
       " 256,\n",
       " 256,\n",
       " 552,\n",
       " 256,\n",
       " 256,\n",
       " 819,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(58, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(60, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(60, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel = resnet50(cfg = cfg1)\n",
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 58,\n",
       " 60,\n",
       " 151,\n",
       " 60,\n",
       " 64,\n",
       " 163,\n",
       " 64,\n",
       " 64,\n",
       " 159,\n",
       " 128,\n",
       " 128,\n",
       " 324,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 128,\n",
       " 128,\n",
       " 319,\n",
       " 256,\n",
       " 256,\n",
       " 978,\n",
       " 256,\n",
       " 256,\n",
       " 708,\n",
       " 256,\n",
       " 256,\n",
       " 824,\n",
       " 256,\n",
       " 256,\n",
       " 521,\n",
       " 256,\n",
       " 256,\n",
       " 552,\n",
       " 256,\n",
       " 256,\n",
       " 819,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = resnet50(cfg = cfg1)\n",
    "new.load_state_dict(torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/BN_layerwise_pruned_75p.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('pruned.pth.tar')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv\n",
    "bn\n",
    "\n",
    "layer1\n",
    "    3conv 3bn\n",
    "    X3\n",
    "layer2\n",
    "    3conv 3bn\n",
    "    X4\n",
    "layer3\n",
    "    3conv 3bn\n",
    "    X6\n",
    "layer4\n",
    "    3conv 3bn\n",
    "    X3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    \"\"\"Base class for backbone networks. Handles freezing layers etc.\n",
    "    args:\n",
    "        frozen_layers  -  Name of layers to freeze. Either list of strings, 'none' or 'all'. Default: 'none'.\n",
    "    \"\"\"\n",
    "    def __init__(self, frozen_layers=()):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(frozen_layers, str):\n",
    "            if frozen_layers.lower() == 'none':\n",
    "                frozen_layers = ()\n",
    "            elif frozen_layers.lower() != 'all':\n",
    "                raise ValueError('Unknown option for frozen layers: \\\"{}\\\". Should be \\\"all\\\", \\\"none\\\" or list of layer names.'.format(frozen_layers))\n",
    "\n",
    "        self.frozen_layers = frozen_layers\n",
    "        self._is_frozen_nograd = False\n",
    "\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        if mode == True:\n",
    "            self._set_frozen_to_eval()\n",
    "        if not self._is_frozen_nograd:\n",
    "            self._set_frozen_to_nograd()\n",
    "            self._is_frozen_nograd = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _set_frozen_to_eval(self):\n",
    "        if isinstance(self.frozen_layers, str) and self.frozen_layers.lower() == 'all':\n",
    "            self.eval()\n",
    "        else:\n",
    "            for layer in self.frozen_layers:\n",
    "                getattr(self, layer).eval()\n",
    "\n",
    "\n",
    "    def _set_frozen_to_nograd(self):\n",
    "        if isinstance(self.frozen_layers, str) and self.frozen_layers.lower() == 'all':\n",
    "            for p in self.parameters():\n",
    "                p.requires_grad_(False)\n",
    "        else:\n",
    "            for layer in self.frozen_layers:\n",
    "                for p in getattr(self, layer).parameters():\n",
    "                    p.requires_grad_(False)\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class channel_selection(nn.Module):\n",
    "    \"\"\"\n",
    "    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n",
    "    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels):\n",
    "        \"\"\"\n",
    "        Initialize the `indexes` with all one vector with the length same as the number of channels.\n",
    "        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n",
    "        \"\"\"\n",
    "        super(channel_selection, self).__init__()\n",
    "        self.indexes = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "        ---------\n",
    "        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n",
    "        \"\"\"\n",
    "        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n",
    "        if selected_index.size == 1:\n",
    "            selected_index = np.resize(selected_index, (1,)) \n",
    "        output = input_tensor[:, :, :, :]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "# from .base import Backbone\n",
    "# from .channel_selection import channel_selection\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, use_bn=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.select = channel_selection(planes*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         out = self.select(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(Backbone):\n",
    "    \"\"\" ResNet network module. Allows extracting specific feature blocks.\"\"\"\n",
    "    def __init__(self, block, layers, output_layers, num_classes=1000, inplanes=64, dilation_factor=1, frozen_layers=()):\n",
    "        self.inplanes = inplanes\n",
    "        super(ResNet, self).__init__(frozen_layers=frozen_layers)\n",
    "        self.output_layers = output_layers\n",
    "        self.conv1 = nn.Conv2d(3, inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]\n",
    "        self.layer1 = self._make_layer(block, inplanes, layers[0], dilation=max(dilation_factor//8, 1))\n",
    "        self.layer2 = self._make_layer(block, inplanes*2, layers[1], stride=stride[0], dilation=max(dilation_factor//4, 1))\n",
    "        self.layer3 = self._make_layer(block, inplanes*4, layers[2], stride=stride[1], dilation=max(dilation_factor//2, 1))\n",
    "        self.layer4 = self._make_layer(block, inplanes*8, layers[3], stride=stride[2], dilation=dilation_factor)\n",
    "\n",
    "        out_feature_strides = {'conv1': 4, 'layer1': 4, 'layer2': 4*stride[0], 'layer3': 4*stride[0]*stride[1],\n",
    "                               'layer4': 4*stride[0]*stride[1]*stride[2]}\n",
    "\n",
    "        # TODO better way?\n",
    "        if isinstance(self.layer1[0], BasicBlock):\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': inplanes, 'layer2': inplanes*2, 'layer3': inplanes*4,\n",
    "                               'layer4': inplanes*8}\n",
    "        elif isinstance(self.layer1[0], Bottleneck):\n",
    "            base_num_channels = 4 * inplanes\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': base_num_channels, 'layer2': base_num_channels * 2,\n",
    "                                    'layer3': base_num_channels * 4, 'layer4': base_num_channels * 8}\n",
    "        else:\n",
    "            raise Exception('block not supported')\n",
    "\n",
    "        self._out_feature_strides = out_feature_strides\n",
    "        self._out_feature_channels = out_feature_channels\n",
    "\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(inplanes*8 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def out_feature_strides(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_strides\n",
    "        else:\n",
    "            return self._out_feature_strides[layer]\n",
    "\n",
    "    def out_feature_channels(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_channels\n",
    "        else:\n",
    "            return self._out_feature_channels[layer]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                channel_selection(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, dilation=dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _add_output_and_check(self, name, x, outputs, output_layers):\n",
    "        if name in output_layers:\n",
    "            outputs[name] = x\n",
    "        return len(output_layers) == len(outputs)\n",
    "\n",
    "    def forward(self, x, output_layers=None):\n",
    "        \"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"\n",
    "        outputs = OrderedDict()\n",
    "\n",
    "        if output_layers is None:\n",
    "            output_layers = self.output_layers\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) ####### select daal dena\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self._add_output_and_check('conv1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        if self._add_output_and_check('layer1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        if self._add_output_and_check('layer2', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        if self._add_output_and_check('layer3', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self._add_output_and_check('layer4', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._add_output_and_check('fc', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        if len(output_layers) == 1 and output_layers[0] == 'default':\n",
    "            return x\n",
    "\n",
    "        raise ValueError('output_layer is wrong.')\n",
    "\n",
    "\n",
    "def resnet_baby(output_layers=None, pretrained=False, inplanes=16, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, inplanes=inplanes, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], progress = False), strict = False )\n",
    "    return model\n",
    "\n",
    "def resnet101(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck,[3, 4, 23, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet101()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/pytracking\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/pytracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.admin.loading import torch_load_legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['layer1.0.select.indexes', 'layer1.0.downsample.2.indexes', 'layer1.1.select.indexes', 'layer1.2.select.indexes', 'layer2.0.select.indexes', 'layer2.0.downsample.2.indexes', 'layer2.1.select.indexes', 'layer2.2.select.indexes', 'layer2.3.select.indexes', 'layer3.0.select.indexes', 'layer3.0.downsample.2.indexes', 'layer3.1.select.indexes', 'layer3.2.select.indexes', 'layer3.3.select.indexes', 'layer3.4.select.indexes', 'layer3.5.select.indexes', 'layer3.6.select.indexes', 'layer3.7.select.indexes', 'layer3.8.select.indexes', 'layer3.9.select.indexes', 'layer3.10.select.indexes', 'layer3.11.select.indexes', 'layer3.12.select.indexes', 'layer3.13.select.indexes', 'layer3.14.select.indexes', 'layer3.15.select.indexes', 'layer3.16.select.indexes', 'layer3.17.select.indexes', 'layer3.18.select.indexes', 'layer3.19.select.indexes', 'layer3.20.select.indexes', 'layer3.21.select.indexes', 'layer3.22.select.indexes', 'layer4.0.select.indexes', 'layer4.0.downsample.2.indexes', 'layer4.1.select.indexes', 'layer4.2.select.indexes'], unexpected_keys=['initializer.filter_conv.weight', 'initializer.filter_conv.bias', 'optimizer.log_step_length', 'optimizer.filter_reg', 'optimizer.label_map_predictor.weight', 'optimizer.target_mask_predictor.0.weight', 'optimizer.spatial_weight_predictor.weight', '_extractor.0.weight', '_1r.0.weight', '_1r.0.bias', '_1r.1.weight', '_1r.1.bias', '_1r.1.running_mean', '_1r.1.running_var', '_1r.1.num_batches_tracked', '_1t.0.weight', '_1t.0.bias', '_1t.1.weight', '_1t.1.bias', '_1t.1.running_mean', '_1t.1.running_var', '_1t.1.num_batches_tracked', '_2t.0.weight', '_2t.0.bias', '_2t.1.weight', '_2t.1.bias', '_2t.1.running_mean', '_2t.1.running_var', '_2t.1.num_batches_tracked', 'r.0.weight', 'r.0.bias', 'r.1.weight', 'r.1.bias', 'r.1.running_mean', 'r.1.running_var', 'r.1.num_batches_tracked', '3r.0.weight', '3r.0.bias', '3r.1.weight', '3r.1.bias', '3r.1.running_mean', '3r.1.running_var', '3r.1.num_batches_tracked', '4r.0.weight', '4r.0.bias', '4r.1.weight', '4r.1.bias', '4r.1.running_mean', '4r.1.running_var', '4r.1.num_batches_tracked', 't.linear.weight', 't.linear.bias', 't.bn.weight', 't.bn.bias', 't.bn.running_mean', 't.bn.running_var', 't.bn.num_batches_tracked', 'redictor.weight', 'redictor.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch_load_legacy('/workspace/tracking_datasets/saved_ckpts/ltr/dimp/sparse/dimp101/DiMPnet_ep0050.pth.tar')['net']\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state = OrderedDict()\n",
    "\n",
    "for key, value in ckpt.items():\n",
    "    key = key[18:] # remove `module.`\n",
    "    new_state[key] = value\n",
    "model.load_state_dict(new_state, strict = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = torch.tensor([4,2,1,3])\n",
    "y,i = torch.sort(bn1)\n",
    "bn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(64.)\n",
      "layer index: 2 \t total channel: 64 \t remaining channel: 64\n",
      "thre: tensor(0.1160)\n",
      "tensor(47.)\n",
      "layer index: 8 \t total channel: 64 \t remaining channel: 47\n",
      "thre: tensor(0.1332)\n",
      "tensor(47.)\n",
      "layer index: 10 \t total channel: 64 \t remaining channel: 47\n",
      "thre: tensor(0.0078)\n",
      "tensor(191.)\n",
      "layer index: 12 \t total channel: 256 \t remaining channel: 191\n",
      "thre: tensor(0.1260)\n",
      "yes\n",
      "tensor(191.) **\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 191\n",
      "thre: tensor(1.9898e-08)\n",
      "tensor(47.)\n",
      "layer index: 21 \t total channel: 64 \t remaining channel: 47\n",
      "thre: tensor(2.5724e-08)\n",
      "tensor(47.)\n",
      "layer index: 23 \t total channel: 64 \t remaining channel: 47\n",
      "thre: tensor(0.0004)\n",
      "tensor(191.)\n",
      "layer index: 25 \t total channel: 256 \t remaining channel: 191\n",
      "thre: tensor(0.1237)\n",
      "tensor(47.)\n",
      "layer index: 30 \t total channel: 64 \t remaining channel: 47\n",
      "thre: tensor(0.1418)\n",
      "tensor(47.)\n",
      "layer index: 32 \t total channel: 64 \t remaining channel: 47\n",
      "thre: tensor(0.0005)\n",
      "tensor(191.)\n",
      "layer index: 34 \t total channel: 256 \t remaining channel: 191\n",
      "thre: tensor(0.1339)\n",
      "tensor(95.)\n",
      "layer index: 40 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.1497)\n",
      "tensor(95.)\n",
      "layer index: 42 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.0003)\n",
      "tensor(383.)\n",
      "layer index: 44 \t total channel: 512 \t remaining channel: 383\n",
      "thre: tensor(0.0252)\n",
      "yes\n",
      "tensor(383.) **\n",
      "layer index: 49 \t total channel: 512 \t remaining channel: 383\n",
      "thre: tensor(0.0571)\n",
      "tensor(95.)\n",
      "layer index: 53 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.0904)\n",
      "tensor(95.)\n",
      "layer index: 55 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.0002)\n",
      "tensor(383.)\n",
      "layer index: 57 \t total channel: 512 \t remaining channel: 383\n",
      "thre: tensor(0.1222)\n",
      "tensor(95.)\n",
      "layer index: 62 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.1306)\n",
      "tensor(95.)\n",
      "layer index: 64 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.0009)\n",
      "tensor(383.)\n",
      "layer index: 66 \t total channel: 512 \t remaining channel: 383\n",
      "thre: tensor(0.1379)\n",
      "tensor(95.)\n",
      "layer index: 71 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.1613)\n",
      "tensor(95.)\n",
      "layer index: 73 \t total channel: 128 \t remaining channel: 95\n",
      "thre: tensor(0.0007)\n",
      "tensor(383.)\n",
      "layer index: 75 \t total channel: 512 \t remaining channel: 383\n",
      "thre: tensor(0.2103)\n",
      "tensor(127.)\n",
      "layer index: 81 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1612)\n",
      "tensor(127.)\n",
      "layer index: 83 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1143)\n",
      "tensor(511.)\n",
      "layer index: 85 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.0815)\n",
      "yes\n",
      "tensor(511.) **\n",
      "layer index: 90 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.0479)\n",
      "tensor(127.)\n",
      "layer index: 94 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0715)\n",
      "tensor(127.)\n",
      "layer index: 96 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0076)\n",
      "tensor(511.)\n",
      "layer index: 98 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.0866)\n",
      "tensor(127.)\n",
      "layer index: 103 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1172)\n",
      "tensor(127.)\n",
      "layer index: 105 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0329)\n",
      "tensor(511.)\n",
      "layer index: 107 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.0727)\n",
      "tensor(127.)\n",
      "layer index: 112 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0917)\n",
      "tensor(127.)\n",
      "layer index: 114 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0123)\n",
      "tensor(511.)\n",
      "layer index: 116 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.0799)\n",
      "tensor(127.)\n",
      "layer index: 121 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0995)\n",
      "tensor(127.)\n",
      "layer index: 123 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0205)\n",
      "tensor(511.)\n",
      "layer index: 125 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1056)\n",
      "tensor(127.)\n",
      "layer index: 130 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1149)\n",
      "tensor(127.)\n",
      "layer index: 132 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0323)\n",
      "tensor(511.)\n",
      "layer index: 134 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1044)\n",
      "tensor(127.)\n",
      "layer index: 139 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1158)\n",
      "tensor(127.)\n",
      "layer index: 141 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0432)\n",
      "tensor(511.)\n",
      "layer index: 143 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1140)\n",
      "tensor(127.)\n",
      "layer index: 148 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1316)\n",
      "tensor(127.)\n",
      "layer index: 150 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0511)\n",
      "tensor(511.)\n",
      "layer index: 152 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1169)\n",
      "tensor(127.)\n",
      "layer index: 157 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1328)\n",
      "tensor(127.)\n",
      "layer index: 159 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0476)\n",
      "tensor(511.)\n",
      "layer index: 161 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1062)\n",
      "tensor(127.)\n",
      "layer index: 166 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1353)\n",
      "tensor(127.)\n",
      "layer index: 168 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0532)\n",
      "tensor(511.)\n",
      "layer index: 170 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1194)\n",
      "tensor(127.)\n",
      "layer index: 175 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1427)\n",
      "tensor(127.)\n",
      "layer index: 177 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0511)\n",
      "tensor(511.)\n",
      "layer index: 179 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1166)\n",
      "tensor(127.)\n",
      "layer index: 184 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1430)\n",
      "tensor(127.)\n",
      "layer index: 186 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0519)\n",
      "tensor(511.)\n",
      "layer index: 188 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1217)\n",
      "tensor(127.)\n",
      "layer index: 193 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1283)\n",
      "tensor(127.)\n",
      "layer index: 195 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0656)\n",
      "tensor(511.)\n",
      "layer index: 197 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1267)\n",
      "tensor(127.)\n",
      "layer index: 202 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1241)\n",
      "tensor(127.)\n",
      "layer index: 204 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0630)\n",
      "tensor(511.)\n",
      "layer index: 206 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1302)\n",
      "tensor(127.)\n",
      "layer index: 211 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1298)\n",
      "tensor(127.)\n",
      "layer index: 213 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0636)\n",
      "tensor(511.)\n",
      "layer index: 215 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1122)\n",
      "tensor(127.)\n",
      "layer index: 220 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1157)\n",
      "tensor(127.)\n",
      "layer index: 222 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0530)\n",
      "tensor(511.)\n",
      "layer index: 224 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1157)\n",
      "tensor(127.)\n",
      "layer index: 229 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1121)\n",
      "tensor(127.)\n",
      "layer index: 231 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0567)\n",
      "tensor(511.)\n",
      "layer index: 233 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1206)\n",
      "tensor(127.)\n",
      "layer index: 238 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1318)\n",
      "tensor(127.)\n",
      "layer index: 240 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0589)\n",
      "tensor(511.)\n",
      "layer index: 242 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1279)\n",
      "tensor(127.)\n",
      "layer index: 247 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1289)\n",
      "tensor(127.)\n",
      "layer index: 249 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0680)\n",
      "tensor(511.)\n",
      "layer index: 251 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1432)\n",
      "tensor(127.)\n",
      "layer index: 256 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1355)\n",
      "tensor(127.)\n",
      "layer index: 258 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0754)\n",
      "tensor(511.)\n",
      "layer index: 260 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1494)\n",
      "tensor(127.)\n",
      "layer index: 265 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1459)\n",
      "tensor(127.)\n",
      "layer index: 267 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0778)\n",
      "tensor(511.)\n",
      "layer index: 269 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1526)\n",
      "tensor(127.)\n",
      "layer index: 274 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1383)\n",
      "tensor(127.)\n",
      "layer index: 276 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0776)\n",
      "tensor(511.)\n",
      "layer index: 278 \t total channel: 1024 \t remaining channel: 511\n",
      "thre: tensor(0.1650)\n",
      "tensor(127.)\n",
      "layer index: 283 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.1542)\n",
      "tensor(127.)\n",
      "layer index: 285 \t total channel: 256 \t remaining channel: 127\n",
      "thre: tensor(0.0832)\n",
      "tensor(511.)\n",
      "layer index: 287 \t total channel: 1024 \t remaining channel: 511\n",
      "tensor(512.)\n",
      "layer index: 293 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(512.)\n",
      "layer index: 295 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(2048.)\n",
      "layer index: 297 \t total channel: 2048 \t remaining channel: 2048\n",
      "yes\n",
      "tensor(2048.) **\n",
      "layer index: 302 \t total channel: 2048 \t remaining channel: 2048\n",
      "tensor(512.)\n",
      "layer index: 306 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(512.)\n",
      "layer index: 308 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(2048.)\n",
      "layer index: 310 \t total channel: 2048 \t remaining channel: 2048\n",
      "tensor(512.)\n",
      "layer index: 315 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(512.)\n",
      "layer index: 317 \t total channel: 512 \t remaining channel: 512\n",
      "tensor(2048.)\n",
      "layer index: 319 \t total channel: 2048 \t remaining channel: 2048\n"
     ]
    }
   ],
   "source": [
    "total1 = 0\n",
    "total2 = 0\n",
    "total3 = 0\n",
    "for idx, m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if idx.split('.')[0] == 'layer1':\n",
    "            total1 += m.weight.data.shape[0]\n",
    "        if idx.split('.')[0] == 'layer2':\n",
    "            total2 += m.weight.data.shape[0]\n",
    "        if idx.split('.')[0] == 'layer3':\n",
    "            total3 += m.weight.data.shape[0]\n",
    "\n",
    "# bn1 = torch.zeros(total1)\n",
    "# bn2 = torch.zeros(total2)\n",
    "# bn3 = torch.zeros(total3)\n",
    "# index1 = 0\n",
    "# index2 = 0\n",
    "# index3 = 0\n",
    "# for (idx, m) in model.named_modules():\n",
    "#     if isinstance(m, nn.BatchNorm2d):\n",
    "#         if idx.split('.')[0] == 'layer1':\n",
    "#             size = m.weight.data.shape[0]\n",
    "#             bn1[index1:(index1+size)] = m.weight.data.abs().clone()\n",
    "#             index1 += size\n",
    "#         if idx.split('.')[0] == 'layer2':\n",
    "#             size = m.weight.data.shape[0]\n",
    "#             bn2[index2:(index2+size)] = m.weight.data.abs().clone()\n",
    "#             index2 += size\n",
    "#         if idx.split('.')[0] == 'layer3':\n",
    "#             size = m.weight.data.shape[0]\n",
    "#             bn3[index3:(index3+size)] = m.weight.data.abs().clone()\n",
    "#             index3 += size\n",
    "            \n",
    "# y1, i = torch.sort(bn1)\n",
    "# thre_index1 = int(total1 * 0.25)\n",
    "# thre1 = y1[thre_index1]\n",
    "\n",
    "# y2, i = torch.sort(bn2)\n",
    "# thre_index2 = int(total2 * 0.25)\n",
    "# thre2 = y2[thre_index2]\n",
    "\n",
    "# y3, i = torch.sort(bn3)\n",
    "# thre_index3 = int(total3 * 0.25)\n",
    "# thre3 = y3[thre_index3]\n",
    "\n",
    "\n",
    "pruned = 0\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "# thre=0.5\n",
    "modules = list(model.named_modules())\n",
    "for k, (idx, m) in enumerate(modules):\n",
    "#     print(idx)\n",
    "    if isinstance(m, nn.BatchNorm2d) :\n",
    "        if idx.split('.')[0] == 'layer1':\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            y1, i1 = torch.sort(weight_copy)\n",
    "            thre_index1 = int(len(y1) * 0.25)\n",
    "            thre1 = y1[thre_index1]\n",
    "            print('thre:',thre1)\n",
    "            mask = weight_copy.gt(thre1).float()\n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "#             if not isinstance(modules[k-2],nn.Sequential):\n",
    "#             print(idx.split('.')[1])\n",
    "            if not idx.split('.')[2]=='downsample':\n",
    "                cfg.append(int(torch.sum(mask)))\n",
    "                print(torch.sum(mask))\n",
    "            else:\n",
    "                print('yes')\n",
    "                print(torch.sum(mask),'**')\n",
    "    #             print(modules[k-2])\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "        elif idx.split('.')[0] == 'layer2':\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            y1, i1 = torch.sort(weight_copy)\n",
    "            thre_index1 = int(len(y1) * 0.25)\n",
    "            thre1 = y1[thre_index1]\n",
    "            print('thre:',thre1)\n",
    "            mask = weight_copy.gt(thre1).float()\n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "#             if not isinstance(modules[k-2],nn.Sequential):\n",
    "            if not idx.split('.')[2]=='downsample':\n",
    "                cfg.append(int(torch.sum(mask)))\n",
    "                print(torch.sum(mask))\n",
    "            else:\n",
    "                print('yes')\n",
    "                print(torch.sum(mask),'**')\n",
    "    #             print(modules[k-2])\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "        elif idx.split('.')[0] == 'layer3':\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            y1, i1 = torch.sort(weight_copy)\n",
    "            thre_index1 = int(len(y1) * 0.5)\n",
    "            thre1 = y1[thre_index1]\n",
    "            print('thre:',thre1)\n",
    "            mask = weight_copy.gt(thre1).float()\n",
    "            pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "            if not idx.split('.')[2]=='downsample':\n",
    "                cfg.append(int(torch.sum(mask)))\n",
    "                print(torch.sum(mask))\n",
    "            else:\n",
    "                print('yes')\n",
    "                print(torch.sum(mask),'**')\n",
    "    #             print(modules[k-2])\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "            \n",
    "        else:\n",
    "            weight_copy = m.weight.data.abs().clone()\n",
    "            mask = weight_copy.gt(0.0).float()\n",
    "#             pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "            m.weight.data.mul_(mask)\n",
    "            m.bias.data.mul_(mask)\n",
    "            try:\n",
    "                if not idx.split('.')[2]=='downsample':\n",
    "                    cfg.append(int(torch.sum(mask)))\n",
    "                    print(torch.sum(mask))\n",
    "                else:\n",
    "                    print('yes')\n",
    "                    print(torch.sum(mask),'**')\n",
    "            except:\n",
    "                cfg.append(int(torch.sum(mask)))\n",
    "                print(torch.sum(mask))\n",
    "    #             print(modules[k-2])\n",
    "            cfg_mask.append(mask.clone())\n",
    "            print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "    elif isinstance(m, nn.MaxPool2d):\n",
    "        cfg.append('M')\n",
    "\n",
    "pruned_ratio = pruned/(total1+total2+total3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4721)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layer index: 2 \t total channel: 64 \t remaining channel: 62\n",
    "layer index: 9 \t total channel: 64 \t remaining channel: 49\n",
    "layer index: 11 \t total channel: 64 \t remaining channel: 53\n",
    "layer index: 13 \t total channel: 256 \t remaining channel: 131\n",
    "layer index: 17 \t total channel: 256 \t remaining channel: 198\n",
    "layer index: 21 \t total channel: 64 \t remaining channel: 56\n",
    "layer index: 23 \t total channel: 64 \t remaining channel: 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 'M',\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "# from .base import Backbone\n",
    "# from .channel_selection import channel_selection\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, use_bn=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None, dilation=1,):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes,cfg[1], kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg[1])\n",
    "        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n",
    "                               padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg[2])\n",
    "        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.select = channel_selection(planes*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         out = self.select(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(Backbone):\n",
    "    \"\"\" ResNet network module. Allows extracting specific feature blocks.\"\"\"\n",
    "    def __init__(self, block, layers, output_layers,cfg = None , num_classes=1000, inplanes=64, dilation_factor=1, frozen_layers=()):\n",
    "        self.inplanes = inplanes\n",
    "        super(ResNet, self).__init__(frozen_layers=frozen_layers)\n",
    "        self.output_layers = output_layers\n",
    "        self.conv1 = nn.Conv2d(3, inplanes , kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]\n",
    "        self.layer1 = self._make_layer(block, inplanes, layers[0], dilation=max(dilation_factor//8, 1), cfg = cfg[0:3*layers[0]])\n",
    "        self.layer2 = self._make_layer(block, inplanes*2, layers[1], stride=stride[0], dilation=max(dilation_factor//4, 1), cfg = cfg[3*layers[0]:3*layers[1]+3*layers[0]])\n",
    "        self.layer3 = self._make_layer(block, inplanes*4, layers[2], stride=stride[1], dilation=max(dilation_factor//2, 1), cfg = cfg[3*layers[1]+3*layers[0]:3*layers[1]+3*layers[0]+3*layers[2]])\n",
    "        self.layer4 = self._make_layer(block, inplanes*8, layers[3], stride=stride[2], dilation=dilation_factor, cfg = cfg[3*layers[1]+3*layers[0]+3*layers[2]:3*layers[1]+3*layers[0]+3*layers[2]+3*layers[3]])\n",
    "\n",
    "        out_feature_strides = {'conv1': 4, 'layer1': 4, 'layer2': 4*stride[0], 'layer3': 4*stride[0]*stride[1],\n",
    "                               'layer4': 4*stride[0]*stride[1]*stride[2]}\n",
    "\n",
    "        # TODO better way?\n",
    "        if isinstance(self.layer1[0], BasicBlock):\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': inplanes, 'layer2': inplanes*2, 'layer3': inplanes*4,\n",
    "                               'layer4': inplanes*8}\n",
    "        elif isinstance(self.layer1[0], Bottleneck):\n",
    "            base_num_channels = 4 * inplanes\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': base_num_channels, 'layer2': base_num_channels * 2,\n",
    "                                    'layer3': base_num_channels * 4, 'layer4': base_num_channels * 8}\n",
    "        else:\n",
    "            raise Exception('block not supported')\n",
    "\n",
    "        self._out_feature_strides = out_feature_strides\n",
    "        self._out_feature_channels = out_feature_channels\n",
    "\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(cfg[-1], num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def out_feature_strides(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_strides\n",
    "        else:\n",
    "            return self._out_feature_strides[layer]\n",
    "\n",
    "    def out_feature_channels(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_channels\n",
    "        else:\n",
    "            return self._out_feature_channels[layer]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, cfg=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                channel_selection(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, cfg[0:3], stride, downsample, dilation=dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, cfg[3*i:3*(i+1)]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _add_output_and_check(self, name, x, outputs, output_layers):\n",
    "        if name in output_layers:\n",
    "            outputs[name] = x\n",
    "        return len(output_layers) == len(outputs)\n",
    "\n",
    "    def forward(self, x, output_layers=None):\n",
    "        \"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"\n",
    "        outputs = OrderedDict()\n",
    "\n",
    "        if output_layers is None:\n",
    "            output_layers = self.output_layers\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) ####### select daal dena\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self._add_output_and_check('conv1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        if self._add_output_and_check('layer1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        if self._add_output_and_check('layer2', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        if self._add_output_and_check('layer3', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self._add_output_and_check('layer4', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._add_output_and_check('fc', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        if len(output_layers) == 1 and output_layers[0] == 'default':\n",
    "            return x\n",
    "\n",
    "        raise ValueError('output_layer is wrong.')\n",
    "\n",
    "\n",
    "def resnet_baby(output_layers=None, pretrained=False, inplanes=16, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, inplanes=inplanes, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(output_layers=None, pretrained=False,cfg = None,**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3],output_layers,cfg=cfg,**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], progress = False), strict = False )\n",
    "    return model\n",
    "\n",
    "def resnet101(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck,[3, 4, 23, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = resnet101(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAHAR ka conv torch.Size([64, 3, 7, 7])\n",
      "CASE 1  torch.Size([47, 64, 1, 1])\n",
      "CASE 2  torch.Size([47, 47, 3, 3])\n",
      "CASE 3  torch.Size([256, 47, 1, 1])\n",
      "DOWN ka conv torch.Size([256, 64, 1, 1])\n",
      "CASE 1  torch.Size([47, 256, 1, 1])\n",
      "CASE 2  torch.Size([47, 47, 3, 3])\n",
      "CASE 3  torch.Size([256, 47, 1, 1])\n",
      "CASE 1  torch.Size([47, 256, 1, 1])\n",
      "CASE 2  torch.Size([47, 47, 3, 3])\n",
      "CASE 3  torch.Size([256, 47, 1, 1])\n",
      "CASE 1  torch.Size([95, 256, 1, 1])\n",
      "CASE 2  torch.Size([95, 95, 3, 3])\n",
      "CASE 3  torch.Size([512, 95, 1, 1])\n",
      "DOWN ka conv torch.Size([512, 256, 1, 1])\n",
      "CASE 1  torch.Size([95, 512, 1, 1])\n",
      "CASE 2  torch.Size([95, 95, 3, 3])\n",
      "CASE 3  torch.Size([512, 95, 1, 1])\n",
      "CASE 1  torch.Size([95, 512, 1, 1])\n",
      "CASE 2  torch.Size([95, 95, 3, 3])\n",
      "CASE 3  torch.Size([512, 95, 1, 1])\n",
      "CASE 1  torch.Size([95, 512, 1, 1])\n",
      "CASE 2  torch.Size([95, 95, 3, 3])\n",
      "CASE 3  torch.Size([512, 95, 1, 1])\n",
      "CASE 1  torch.Size([127, 512, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "DOWN ka conv torch.Size([1024, 512, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([127, 1024, 1, 1])\n",
      "CASE 2  torch.Size([127, 127, 3, 3])\n",
      "CASE 3  torch.Size([1024, 127, 1, 1])\n",
      "CASE 1  torch.Size([512, 1024, 1, 1])\n",
      "CASE 2  torch.Size([512, 512, 3, 3])\n",
      "CASE 3  torch.Size([2048, 512, 1, 1])\n",
      "DOWN ka conv torch.Size([2048, 1024, 1, 1])\n",
      "CASE 1  torch.Size([512, 2048, 1, 1])\n",
      "CASE 2  torch.Size([512, 512, 3, 3])\n",
      "CASE 3  torch.Size([2048, 512, 1, 1])\n",
      "CASE 1  torch.Size([512, 2048, 1, 1])\n",
      "CASE 2  torch.Size([512, 512, 3, 3])\n",
      "CASE 3  torch.Size([2048, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "newmodel = resnet101(cfg=cfg)\n",
    "old_modules = list(model.modules())\n",
    "new_modules = list(newmodel.modules())\n",
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "conv_count = 0\n",
    "first_bn = False\n",
    "\n",
    "for layer_id in range(len(old_modules)):\n",
    "    m0 = old_modules[layer_id]\n",
    "    m1 = new_modules[layer_id]\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        if first_bn==False:\n",
    "            first_bn=True\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "            continue\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "        if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "            # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "\n",
    "            # We need to set the channel selection layer.\n",
    "            m2 = new_modules[layer_id + 1]\n",
    "            m2.indexes.data.zero_()\n",
    "            m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        else:\n",
    "            m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "            m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "            m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "            m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "    \n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        if conv_count == 0:\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            conv_count += 1\n",
    "            print(\"BAHAR ka conv\", m1.weight.data.shape)\n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+2], nn.Conv2d) and not isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "            # Residual first case\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            w1 = m0.weight.data[idx1.tolist(), :, :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            print(\"CASE 1 \", m1.weight.data.shape)\n",
    "#             if conv_count % 3 != 1:           \n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+2], nn.Conv2d) and isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "            # Residual second case\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            print(\"CASE 2 \", m1.weight.data.shape)\n",
    "#             if conv_count % 3 != 1:           \n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+3], nn.ReLU) and isinstance(old_modules[layer_id+2], channel_selection):\n",
    "            # Residual third case\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#             print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            print(\"CASE 3 \", m1.weight.data.shape)\n",
    "            continue\n",
    "        m1.weight.data = m0.weight.data.clone()\n",
    "        print(\"DOWN ka conv\", m1.weight.data.shape)\n",
    " \n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        if idx0.size == 1:\n",
    "            idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "        m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "        m1.bias.data = m0.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# newmodel = resnet101(cfg=cfg)\n",
    "# old_modules = list(model.modules())\n",
    "# new_modules = list(newmodel.modules())\n",
    "# layer_id_in_cfg = 0\n",
    "# start_mask = torch.ones(3)\n",
    "# end_mask = cfg_mask[layer_id_in_cfg]\n",
    "# conv_count = 0\n",
    "# first_bn = False\n",
    "\n",
    "# for layer_id in range(len(old_modules)):\n",
    "#     m0 = old_modules[layer_id]\n",
    "#     m1 = new_modules[layer_id]\n",
    "#     if isinstance(m0, nn.BatchNorm2d):\n",
    "#         if first_bn==False:\n",
    "#             first_bn=True\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             m1.bias.data = m0.bias.data.clone()\n",
    "#             m1.running_mean = m0.running_mean.clone()\n",
    "#             m1.running_var = m0.running_var.clone()\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "#             continue\n",
    "#         idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "#         if idx1.size == 1:\n",
    "#             idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "#         if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "#             # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             m1.bias.data = m0.bias.data.clone()\n",
    "#             m1.running_mean = m0.running_mean.clone()\n",
    "#             m1.running_var = m0.running_var.clone()\n",
    "\n",
    "#             # We need to set the channel selection layer.\n",
    "#             m2 = new_modules[layer_id + 1]\n",
    "#             m2.indexes.data.zero_()\n",
    "#             m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "#         else:\n",
    "#             m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "#             m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "#             m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "#             m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "#             layer_id_in_cfg += 1\n",
    "#             start_mask = end_mask.clone()\n",
    "#             if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "#                 end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "    \n",
    "#     elif isinstance(m0, nn.Conv2d):\n",
    "#         if conv_count == 0:\n",
    "#             m1.weight.data = m0.weight.data.clone()\n",
    "#             conv_count += 1\n",
    "#             print(\"BAHAR ka conv\", m1.weight.data.shape)\n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id+2], nn.Conv2d) and not isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "#             # Residual first case\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "# #             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "# #             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "#             w1 = m0.weight.data[idx1.tolist(), :, :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             print(\"CASE 1 \", m1.weight.data.shape)\n",
    "# #             if conv_count % 3 != 1:           \n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id+2], nn.Conv2d) and isinstance(old_modules[layer_id-1], nn.BatchNorm2d):\n",
    "#             # Residual second case\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "# #             print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "#             w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             print(\"CASE 2 \", m1.weight.data.shape)\n",
    "# #             if conv_count % 3 != 1:           \n",
    "#             continue\n",
    "#         if isinstance(old_modules[layer_id+3], nn.ReLU) and isinstance(old_modules[layer_id+2], channel_selection):\n",
    "#             # Residual third case\n",
    "#             conv_count += 1\n",
    "#             idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#             idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "# #             print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "#             if idx0.size == 1:\n",
    "#                 idx0 = np.resize(idx0, (1,))\n",
    "#             if idx1.size == 1:\n",
    "#                 idx1 = np.resize(idx1, (1,))\n",
    "#             w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "#             m1.weight.data = w1.clone()\n",
    "#             print(\"CASE 3 \", m1.weight.data.shape)\n",
    "#             continue\n",
    "#         m1.weight.data = m0.weight.data.clone()\n",
    "#         print(\"DOWN ka conv\", m1.weight.data.shape)\n",
    " \n",
    "#     elif isinstance(m0, nn.Linear):\n",
    "#         idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "#         if idx0.size == 1:\n",
    "#             idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "#         m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "#         m1.bias.data = m0.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()},'/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_50p.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()},'/workspace/tracking_datasets/pruned_ckpts/dimp101_correct/modified_batchnorm_layerwise_pruned_50p.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.load_state_dict(torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp101_correct/modified_batchnorm_layerwise_pruned_50p.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_75p.pth.tar')['state_dict']['layer1.1.conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_75p.pth.tar')['state_dict']['layer1.1.conv2.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/layerwise_pruned_75p.pth.tar')['state_dict']['layer1.1.conv3.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg1 = torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp101_correct/modified_batchnorm_layerwise_pruned_50p.pth.tar')['cfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(47, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(47, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 95, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(95, 95, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(95, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(95, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 127, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(127, 127, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(127, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(127, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel = resnet101(cfg = cfg1)\n",
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 47,\n",
       " 47,\n",
       " 191,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 95,\n",
       " 95,\n",
       " 383,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 127,\n",
       " 127,\n",
       " 511,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = resnet101(cfg = cfg1)\n",
    "new.load_state_dict(torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp101_correct/modified_batchnorm_layerwise_pruned_50p.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('pruned.pth.tar')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv\n",
    "bn\n",
    "\n",
    "layer1\n",
    "    3conv 3bn\n",
    "    X3\n",
    "layer2\n",
    "    3conv 3bn\n",
    "    X4\n",
    "layer3\n",
    "    3conv 3bn\n",
    "    X6\n",
    "layer4\n",
    "    3conv 3bn\n",
    "    X3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

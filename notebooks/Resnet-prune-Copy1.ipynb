{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Backbone(nn.Module):\n",
    "    \"\"\"Base class for backbone networks. Handles freezing layers etc.\n",
    "    args:\n",
    "        frozen_layers  -  Name of layers to freeze. Either list of strings, 'none' or 'all'. Default: 'none'.\n",
    "    \"\"\"\n",
    "    def __init__(self, frozen_layers=()):\n",
    "        super().__init__()\n",
    "\n",
    "        if isinstance(frozen_layers, str):\n",
    "            if frozen_layers.lower() == 'none':\n",
    "                frozen_layers = ()\n",
    "            elif frozen_layers.lower() != 'all':\n",
    "                raise ValueError('Unknown option for frozen layers: \\\"{}\\\". Should be \\\"all\\\", \\\"none\\\" or list of layer names.'.format(frozen_layers))\n",
    "\n",
    "        self.frozen_layers = frozen_layers\n",
    "        self._is_frozen_nograd = False\n",
    "\n",
    "\n",
    "    def train(self, mode=True):\n",
    "        super().train(mode)\n",
    "        if mode == True:\n",
    "            self._set_frozen_to_eval()\n",
    "        if not self._is_frozen_nograd:\n",
    "            self._set_frozen_to_nograd()\n",
    "            self._is_frozen_nograd = True\n",
    "        return self\n",
    "\n",
    "\n",
    "    def _set_frozen_to_eval(self):\n",
    "        if isinstance(self.frozen_layers, str) and self.frozen_layers.lower() == 'all':\n",
    "            self.eval()\n",
    "        else:\n",
    "            for layer in self.frozen_layers:\n",
    "                getattr(self, layer).eval()\n",
    "\n",
    "\n",
    "    def _set_frozen_to_nograd(self):\n",
    "        if isinstance(self.frozen_layers, str) and self.frozen_layers.lower() == 'all':\n",
    "            for p in self.parameters():\n",
    "                p.requires_grad_(False)\n",
    "        else:\n",
    "            for layer in self.frozen_layers:\n",
    "                for p in getattr(self, layer).parameters():\n",
    "                    p.requires_grad_(False)\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class channel_selection(nn.Module):\n",
    "    \"\"\"\n",
    "    Select channels from the output of BatchNorm2d layer. It should be put directly after BatchNorm2d layer.\n",
    "    The output shape of this layer is determined by the number of 1 in `self.indexes`.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_channels):\n",
    "        \"\"\"\n",
    "        Initialize the `indexes` with all one vector with the length same as the number of channels.\n",
    "        During pruning, the places in `indexes` which correpond to the channels to be pruned will be set to 0.\n",
    "        \"\"\"\n",
    "        super(channel_selection, self).__init__()\n",
    "        self.indexes = nn.Parameter(torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        \"\"\"\n",
    "        Parameter\n",
    "        ---------\n",
    "        input_tensor: (N,C,H,W). It should be the output of BatchNorm2d layer.\n",
    "        \"\"\"\n",
    "        selected_index = np.squeeze(np.argwhere(self.indexes.data.cpu().numpy()))\n",
    "        if selected_index.size == 1:\n",
    "            selected_index = np.resize(selected_index, (1,)) \n",
    "        output = input_tensor[:, :, :, :]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "# from .base import Backbone\n",
    "# from .channel_selection import channel_selection\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, use_bn=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.select = channel_selection(planes*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         out = self.select(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(Backbone):\n",
    "    \"\"\" ResNet network module. Allows extracting specific feature blocks.\"\"\"\n",
    "    def __init__(self, block, layers, output_layers, num_classes=1000, inplanes=64, dilation_factor=1, frozen_layers=()):\n",
    "        self.inplanes = inplanes\n",
    "        super(ResNet, self).__init__(frozen_layers=frozen_layers)\n",
    "        self.output_layers = output_layers\n",
    "        self.conv1 = nn.Conv2d(3, inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]\n",
    "        self.layer1 = self._make_layer(block, inplanes, layers[0], dilation=max(dilation_factor//8, 1))\n",
    "        self.layer2 = self._make_layer(block, inplanes*2, layers[1], stride=stride[0], dilation=max(dilation_factor//4, 1))\n",
    "        self.layer3 = self._make_layer(block, inplanes*4, layers[2], stride=stride[1], dilation=max(dilation_factor//2, 1))\n",
    "        self.layer4 = self._make_layer(block, inplanes*8, layers[3], stride=stride[2], dilation=dilation_factor)\n",
    "\n",
    "        out_feature_strides = {'conv1': 4, 'layer1': 4, 'layer2': 4*stride[0], 'layer3': 4*stride[0]*stride[1],\n",
    "                               'layer4': 4*stride[0]*stride[1]*stride[2]}\n",
    "\n",
    "        # TODO better way?\n",
    "        if isinstance(self.layer1[0], BasicBlock):\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': inplanes, 'layer2': inplanes*2, 'layer3': inplanes*4,\n",
    "                               'layer4': inplanes*8}\n",
    "        elif isinstance(self.layer1[0], Bottleneck):\n",
    "            base_num_channels = 4 * inplanes\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': base_num_channels, 'layer2': base_num_channels * 2,\n",
    "                                    'layer3': base_num_channels * 4, 'layer4': base_num_channels * 8}\n",
    "        else:\n",
    "            raise Exception('block not supported')\n",
    "\n",
    "        self._out_feature_strides = out_feature_strides\n",
    "        self._out_feature_channels = out_feature_channels\n",
    "\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(inplanes*8 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def out_feature_strides(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_strides\n",
    "        else:\n",
    "            return self._out_feature_strides[layer]\n",
    "\n",
    "    def out_feature_channels(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_channels\n",
    "        else:\n",
    "            return self._out_feature_channels[layer]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                channel_selection(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, dilation=dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _add_output_and_check(self, name, x, outputs, output_layers):\n",
    "        if name in output_layers:\n",
    "            outputs[name] = x\n",
    "        return len(output_layers) == len(outputs)\n",
    "\n",
    "    def forward(self, x, output_layers=None):\n",
    "        \"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"\n",
    "        outputs = OrderedDict()\n",
    "\n",
    "        if output_layers is None:\n",
    "            output_layers = self.output_layers\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) ####### select daal dena\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self._add_output_and_check('conv1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        if self._add_output_and_check('layer1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        if self._add_output_and_check('layer2', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        if self._add_output_and_check('layer3', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self._add_output_and_check('layer4', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._add_output_and_check('fc', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        if len(output_layers) == 1 and output_layers[0] == 'default':\n",
    "            return x\n",
    "\n",
    "        raise ValueError('output_layer is wrong.')\n",
    "\n",
    "\n",
    "def resnet_baby(output_layers=None, pretrained=False, inplanes=16, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, inplanes=inplanes, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], output_layers, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], progress = False), strict = False )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): channel_selection()\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (select): channel_selection()\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet50()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/pytracking\n"
     ]
    }
   ],
   "source": [
    "cd /workspace/pytracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.admin.loading import torch_load_legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['layer1.0.select.indexes', 'layer1.0.downsample.2.indexes', 'layer1.1.select.indexes', 'layer1.2.select.indexes', 'layer2.0.select.indexes', 'layer2.0.downsample.2.indexes', 'layer2.1.select.indexes', 'layer2.2.select.indexes', 'layer2.3.select.indexes', 'layer3.0.select.indexes', 'layer3.0.downsample.2.indexes', 'layer3.1.select.indexes', 'layer3.2.select.indexes', 'layer3.3.select.indexes', 'layer3.4.select.indexes', 'layer3.5.select.indexes', 'layer4.0.select.indexes', 'layer4.0.downsample.2.indexes', 'layer4.1.select.indexes', 'layer4.2.select.indexes'], unexpected_keys=['initializer.filter_conv.weight', 'initializer.filter_conv.bias', 'optimizer.log_step_length', 'optimizer.filter_reg', 'optimizer.label_map_predictor.weight', 'optimizer.target_mask_predictor.0.weight', 'optimizer.spatial_weight_predictor.weight', '_extractor.0.weight', '_1r.0.weight', '_1r.0.bias', '_1r.1.weight', '_1r.1.bias', '_1r.1.running_mean', '_1r.1.running_var', '_1r.1.num_batches_tracked', '_1t.0.weight', '_1t.0.bias', '_1t.1.weight', '_1t.1.bias', '_1t.1.running_mean', '_1t.1.running_var', '_1t.1.num_batches_tracked', '_2t.0.weight', '_2t.0.bias', '_2t.1.weight', '_2t.1.bias', '_2t.1.running_mean', '_2t.1.running_var', '_2t.1.num_batches_tracked', 'r.0.weight', 'r.0.bias', 'r.1.weight', 'r.1.bias', 'r.1.running_mean', 'r.1.running_var', 'r.1.num_batches_tracked', '3r.0.weight', '3r.0.bias', '3r.1.weight', '3r.1.bias', '3r.1.running_mean', '3r.1.running_var', '3r.1.num_batches_tracked', '4r.0.weight', '4r.0.bias', '4r.1.weight', '4r.1.bias', '4r.1.running_mean', '4r.1.running_var', '4r.1.num_batches_tracked', 't.linear.weight', 't.linear.bias', 't.bn.weight', 't.bn.bias', 't.bn.running_mean', 't.bn.running_var', 't.bn.num_batches_tracked', 'redictor.weight', 'redictor.bias'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch_load_legacy('../tracking_datasets/saved_ckpts/ltr/dimp/sparse-pretrained/dimp50/DiMPnet_ep0050.pth.tar')['net']\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state = OrderedDict()\n",
    "\n",
    "for key, value in ckpt.items():\n",
    "    key = key[18:] # remove `module.`\n",
    "    new_state[key] = value\n",
    "model.load_state_dict(new_state, strict = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn1\n",
      "layer1.0.bn1\n",
      "layer1.0.bn2\n",
      "layer1.0.bn3\n",
      "layer1.0.downsample.1\n",
      "layer1.1.bn1\n",
      "layer1.1.bn2\n",
      "layer1.1.bn3\n",
      "layer1.2.bn1\n",
      "layer1.2.bn2\n",
      "layer1.2.bn3\n",
      "layer2.0.bn1\n",
      "layer2.0.bn2\n",
      "layer2.0.bn3\n",
      "layer2.0.downsample.1\n",
      "layer2.1.bn1\n",
      "layer2.1.bn2\n",
      "layer2.1.bn3\n",
      "layer2.2.bn1\n",
      "layer2.2.bn2\n",
      "layer2.2.bn3\n",
      "layer2.3.bn1\n",
      "layer2.3.bn2\n",
      "layer2.3.bn3\n",
      "layer3.0.bn1\n",
      "layer3.0.bn2\n",
      "layer3.0.bn3\n",
      "layer3.0.downsample.1\n",
      "layer3.1.bn1\n",
      "layer3.1.bn2\n",
      "layer3.1.bn3\n",
      "layer3.2.bn1\n",
      "layer3.2.bn2\n",
      "layer3.2.bn3\n",
      "layer3.3.bn1\n",
      "layer3.3.bn2\n",
      "layer3.3.bn3\n",
      "layer3.4.bn1\n",
      "layer3.4.bn2\n",
      "layer3.4.bn3\n",
      "layer3.5.bn1\n",
      "layer3.5.bn2\n",
      "layer3.5.bn3\n",
      "layer4.0.bn1 ****\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "layer4.0.bn1\n",
      "layer4.0.bn2 ****\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "layer4.0.bn2\n",
      "layer4.0.bn3 ****\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "layer4.0.bn3\n",
      "layer4.0.downsample.1 ****\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "layer4.0.downsample.1\n",
      "layer4.1.bn1 ****\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "layer4.1.bn1\n",
      "layer4.1.bn2 ****\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "layer4.1.bn2\n",
      "layer4.1.bn3 ****\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "layer4.1.bn3\n",
      "layer4.2.bn1 ****\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "layer4.2.bn1\n",
      "layer4.2.bn2 ****\n",
      "torch.Size([512])\n",
      "torch.Size([512])\n",
      "layer4.2.bn2\n",
      "layer4.2.bn3 ****\n",
      "torch.Size([2048])\n",
      "torch.Size([2048])\n",
      "layer4.2.bn3\n"
     ]
    }
   ],
   "source": [
    "for idx, m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        \n",
    "        if idx.split('.')[0] == 'layer4':\n",
    "            print(idx, '****')\n",
    "            print(m.weight.shape)\n",
    "            torch.nn.init.ones_(m.weight)\n",
    "            print(m.weight.shape)\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer index: 2 \t total channel: 64 \t remaining channel: 62\n",
      "layer index: 8 \t total channel: 64 \t remaining channel: 47\n",
      "layer index: 10 \t total channel: 64 \t remaining channel: 53\n",
      "layer index: 12 \t total channel: 256 \t remaining channel: 133\n",
      "layer index: 17 \t total channel: 256 \t remaining channel: 200\n",
      "layer index: 21 \t total channel: 64 \t remaining channel: 56\n",
      "layer index: 23 \t total channel: 64 \t remaining channel: 60\n",
      "layer index: 25 \t total channel: 256 \t remaining channel: 63\n",
      "layer index: 30 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 32 \t total channel: 64 \t remaining channel: 63\n",
      "layer index: 34 \t total channel: 256 \t remaining channel: 67\n",
      "layer index: 40 \t total channel: 128 \t remaining channel: 127\n",
      "layer index: 42 \t total channel: 128 \t remaining channel: 128\n",
      "layer index: 44 \t total channel: 512 \t remaining channel: 221\n",
      "layer index: 49 \t total channel: 512 \t remaining channel: 224\n",
      "layer index: 53 \t total channel: 128 \t remaining channel: 43\n",
      "layer index: 55 \t total channel: 128 \t remaining channel: 109\n",
      "layer index: 57 \t total channel: 512 \t remaining channel: 144\n",
      "layer index: 62 \t total channel: 128 \t remaining channel: 116\n",
      "layer index: 64 \t total channel: 128 \t remaining channel: 118\n",
      "layer index: 66 \t total channel: 512 \t remaining channel: 168\n",
      "layer index: 71 \t total channel: 128 \t remaining channel: 123\n",
      "layer index: 73 \t total channel: 128 \t remaining channel: 127\n",
      "layer index: 75 \t total channel: 512 \t remaining channel: 147\n",
      "layer index: 81 \t total channel: 256 \t remaining channel: 256\n",
      "layer index: 83 \t total channel: 256 \t remaining channel: 255\n",
      "layer index: 85 \t total channel: 1024 \t remaining channel: 569\n",
      "layer index: 90 \t total channel: 1024 \t remaining channel: 299\n",
      "layer index: 94 \t total channel: 256 \t remaining channel: 217\n",
      "layer index: 96 \t total channel: 256 \t remaining channel: 247\n",
      "layer index: 98 \t total channel: 1024 \t remaining channel: 247\n",
      "layer index: 103 \t total channel: 256 \t remaining channel: 216\n",
      "layer index: 105 \t total channel: 256 \t remaining channel: 247\n",
      "layer index: 107 \t total channel: 1024 \t remaining channel: 181\n",
      "layer index: 112 \t total channel: 256 \t remaining channel: 233\n",
      "layer index: 114 \t total channel: 256 \t remaining channel: 242\n",
      "layer index: 116 \t total channel: 1024 \t remaining channel: 208\n",
      "layer index: 121 \t total channel: 256 \t remaining channel: 238\n",
      "layer index: 123 \t total channel: 256 \t remaining channel: 242\n",
      "layer index: 125 \t total channel: 1024 \t remaining channel: 254\n",
      "layer index: 130 \t total channel: 256 \t remaining channel: 251\n",
      "layer index: 132 \t total channel: 256 \t remaining channel: 254\n",
      "layer index: 134 \t total channel: 1024 \t remaining channel: 329\n",
      "layer index: 140 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 142 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 144 \t total channel: 2048 \t remaining channel: 2048\n",
      "layer index: 149 \t total channel: 2048 \t remaining channel: 2048\n",
      "layer index: 153 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 155 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 157 \t total channel: 2048 \t remaining channel: 2048\n",
      "layer index: 162 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 164 \t total channel: 512 \t remaining channel: 512\n",
      "layer index: 166 \t total channel: 2048 \t remaining channel: 2048\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "for idx, m in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if idx.split('.')[0] != 'layer4':\n",
    "            \n",
    "            total += m.weight.data.shape[0]\n",
    "\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for (idx, m) in model.named_modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        if idx.split('.')[0] != 'layer4':\n",
    "            size = m.weight.data.shape[0]\n",
    "            bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "            index += size\n",
    "\n",
    "y, i = torch.sort(bn)\n",
    "thre_index = int(total * 0.5)\n",
    "thre = y[thre_index]\n",
    "\n",
    "\n",
    "pruned = 0\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "modules = list(model.modules())\n",
    "for k, (idx, m) in enumerate(model.named_modules()):\n",
    "    if isinstance(m, nn.BatchNorm2d) :\n",
    "        weight_copy = m.weight.data.abs().clone()\n",
    "        mask = weight_copy.gt(thre).float()\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "        m.weight.data.mul_(mask)\n",
    "        m.bias.data.mul_(mask)\n",
    "        if isinstance(modules[k-3],channel_selection)==False:\n",
    "            cfg.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.clone())\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "    elif isinstance(m, nn.MaxPool2d):\n",
    "        cfg.append('M')\n",
    "\n",
    "pruned_ratio = pruned/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62,\n",
       " 47,\n",
       " 53,\n",
       " 133,\n",
       " 200,\n",
       " 60,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 67,\n",
       " 127,\n",
       " 128,\n",
       " 221,\n",
       " 224,\n",
       " 109,\n",
       " 144,\n",
       " 116,\n",
       " 118,\n",
       " 168,\n",
       " 123,\n",
       " 127,\n",
       " 147,\n",
       " 256,\n",
       " 255,\n",
       " 569,\n",
       " 299,\n",
       " 247,\n",
       " 247,\n",
       " 216,\n",
       " 247,\n",
       " 181,\n",
       " 233,\n",
       " 242,\n",
       " 208,\n",
       " 238,\n",
       " 242,\n",
       " 254,\n",
       " 251,\n",
       " 254,\n",
       " 329,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 2048,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cfg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layer index: 2 \t total channel: 64 \t remaining channel: 62\n",
    "layer index: 9 \t total channel: 64 \t remaining channel: 49\n",
    "layer index: 11 \t total channel: 64 \t remaining channel: 53\n",
    "layer index: 13 \t total channel: 256 \t remaining channel: 131\n",
    "layer index: 17 \t total channel: 256 \t remaining channel: 198\n",
    "layer index: 21 \t total channel: 64 \t remaining channel: 56\n",
    "layer index: 23 \t total channel: 64 \t remaining channel: 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5469e-12, 1.3583e-10, 2.2824e-10,  ..., 5.0624e-01, 5.0981e-01,\n",
       "        5.2134e-01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62,\n",
       " 'M',\n",
       " 47,\n",
       " 53,\n",
       " 133,\n",
       " 200,\n",
       " 60,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 67,\n",
       " 127,\n",
       " 128,\n",
       " 221,\n",
       " 224,\n",
       " 109,\n",
       " 144,\n",
       " 116,\n",
       " 118,\n",
       " 168,\n",
       " 123,\n",
       " 127,\n",
       " 147,\n",
       " 256,\n",
       " 255,\n",
       " 569,\n",
       " 299,\n",
       " 247,\n",
       " 247,\n",
       " 216,\n",
       " 247,\n",
       " 181,\n",
       " 233,\n",
       " 242,\n",
       " 208,\n",
       " 238,\n",
       " 242,\n",
       " 254,\n",
       " 251,\n",
       " 254,\n",
       " 329,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 2048,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import model_urls\n",
    "# from .base import Backbone\n",
    "# from .channel_selection import channel_selection\n",
    "\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, use_bn=True):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.use_bn = use_bn\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes, dilation=dilation)\n",
    "\n",
    "        if use_bn:\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, cfg, stride=1, downsample=None, dilation=1,):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(cfg[0],cfg[1], kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg[1])\n",
    "        self.conv2 = nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=stride,\n",
    "                               padding=dilation, bias=False, dilation=dilation)\n",
    "        self.bn2 = nn.BatchNorm2d(cfg[2])\n",
    "        self.conv3 = nn.Conv2d(cfg[2], planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.select = channel_selection(planes*4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "#         out = self.select(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(Backbone):\n",
    "    \"\"\" ResNet network module. Allows extracting specific feature blocks.\"\"\"\n",
    "    def __init__(self, block, layers, output_layers,cfg = None , num_classes=1000, inplanes=64, dilation_factor=1, frozen_layers=()):\n",
    "        self.inplanes = inplanes\n",
    "        super(ResNet, self).__init__(frozen_layers=frozen_layers)\n",
    "        self.output_layers = output_layers\n",
    "        self.conv1 = nn.Conv2d(3, cfg[0], kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(cfg[0])\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]\n",
    "        self.layer1 = self._make_layer(block, inplanes, layers[0], dilation=max(dilation_factor//8, 1), cfg = cfg[0:3*layers[0]])\n",
    "        self.layer2 = self._make_layer(block, inplanes*2, layers[1], stride=stride[0], dilation=max(dilation_factor//4, 1), cfg = cfg[3*layers[0]:3*layers[1]+3*layers[0]])\n",
    "        self.layer3 = self._make_layer(block, inplanes*4, layers[2], stride=stride[1], dilation=max(dilation_factor//2, 1), cfg = cfg[3*layers[1]+3*layers[0]:3*layers[1]+3*layers[0]+3*layers[2]])\n",
    "        self.layer4 = self._make_layer(block, inplanes*8, layers[3], stride=stride[2], dilation=dilation_factor, cfg = cfg[3*layers[1]+3*layers[0]+3*layers[2]:3*layers[1]+3*layers[0]+3*layers[2]+3*layers[3]])\n",
    "\n",
    "        out_feature_strides = {'conv1': 4, 'layer1': 4, 'layer2': 4*stride[0], 'layer3': 4*stride[0]*stride[1],\n",
    "                               'layer4': 4*stride[0]*stride[1]*stride[2]}\n",
    "\n",
    "        # TODO better way?\n",
    "        if isinstance(self.layer1[0], BasicBlock):\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': inplanes, 'layer2': inplanes*2, 'layer3': inplanes*4,\n",
    "                               'layer4': inplanes*8}\n",
    "        elif isinstance(self.layer1[0], Bottleneck):\n",
    "            base_num_channels = 4 * inplanes\n",
    "            out_feature_channels = {'conv1': inplanes, 'layer1': base_num_channels, 'layer2': base_num_channels * 2,\n",
    "                                    'layer3': base_num_channels * 4, 'layer4': base_num_channels * 8}\n",
    "        else:\n",
    "            raise Exception('block not supported')\n",
    "\n",
    "        self._out_feature_strides = out_feature_strides\n",
    "        self._out_feature_channels = out_feature_channels\n",
    "\n",
    "        # self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(cfg[-1], num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def out_feature_strides(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_strides\n",
    "        else:\n",
    "            return self._out_feature_strides[layer]\n",
    "\n",
    "    def out_feature_channels(self, layer=None):\n",
    "        if layer is None:\n",
    "            return self._out_feature_channels\n",
    "        else:\n",
    "            return self._out_feature_channels[layer]\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1, cfg=None):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "                channel_selection(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, cfg[0:3], stride, downsample, dilation=dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, cfg[3*i:3*(i+1)]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _add_output_and_check(self, name, x, outputs, output_layers):\n",
    "        if name in output_layers:\n",
    "            outputs[name] = x\n",
    "        return len(output_layers) == len(outputs)\n",
    "\n",
    "    def forward(self, x, output_layers=None):\n",
    "        \"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"\n",
    "        outputs = OrderedDict()\n",
    "\n",
    "        if output_layers is None:\n",
    "            output_layers = self.output_layers\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x) ####### select daal dena\n",
    "        x = self.relu(x)\n",
    "\n",
    "        if self._add_output_and_check('conv1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "\n",
    "        if self._add_output_and_check('layer1', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        if self._add_output_and_check('layer2', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        if self._add_output_and_check('layer3', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self._add_output_and_check('layer4', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        if self._add_output_and_check('fc', x, outputs, output_layers):\n",
    "            return outputs\n",
    "\n",
    "        if len(output_layers) == 1 and output_layers[0] == 'default':\n",
    "            return x\n",
    "\n",
    "        raise ValueError('output_layer is wrong.')\n",
    "\n",
    "\n",
    "def resnet_baby(output_layers=None, pretrained=False, inplanes=16, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, inplanes=inplanes, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        raise NotImplementedError\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet18(output_layers=None, pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], output_layers, **kwargs)\n",
    "\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(output_layers=None, pretrained=False,cfg = None,**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    \"\"\"\n",
    "\n",
    "    if output_layers is None:\n",
    "        output_layers = ['default']\n",
    "    else:\n",
    "        for l in output_layers:\n",
    "            if l not in ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']:\n",
    "                raise ValueError('Unknown layer: {}'.format(l))\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3],output_layers,cfg=cfg,**kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50'], progress = False), strict = False )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.pop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[62,\n",
       " 47,\n",
       " 53,\n",
       " 133,\n",
       " 200,\n",
       " 60,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 67,\n",
       " 127,\n",
       " 128,\n",
       " 221,\n",
       " 224,\n",
       " 109,\n",
       " 144,\n",
       " 116,\n",
       " 118,\n",
       " 168,\n",
       " 123,\n",
       " 127,\n",
       " 147,\n",
       " 256,\n",
       " 255,\n",
       " 569,\n",
       " 299,\n",
       " 247,\n",
       " 247,\n",
       " 216,\n",
       " 247,\n",
       " 181,\n",
       " 233,\n",
       " 242,\n",
       " 208,\n",
       " 238,\n",
       " 242,\n",
       " 254,\n",
       " 251,\n",
       " 254,\n",
       " 329,\n",
       " 512,\n",
       " 512,\n",
       " 2048,\n",
       " 2048,\n",
       " 512,\n",
       " 2048,\n",
       " 512,\n",
       " 512,\n",
       " 2048]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = resnet50(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAHAR ka conv\n",
      "CASE 1 \n",
      "In shape: 62, Out shape 47**.\n",
      "CASE 1 \n",
      "In shape: 47, Out shape 53**.\n",
      "CASE 2 \n",
      "In shape: 53, Out shape 133.\n",
      "DOWN ka conv\n",
      "CASE 1 \n",
      "In shape: 200, Out shape 56**.\n",
      "CASE 1 \n",
      "In shape: 56, Out shape 60**.\n",
      "CASE 2 \n",
      "In shape: 60, Out shape 63.\n",
      "CASE 1 \n",
      "In shape: 63, Out shape 63**.\n",
      "CASE 1 \n",
      "In shape: 63, Out shape 63**.\n",
      "CASE 2 \n",
      "In shape: 63, Out shape 67.\n",
      "CASE 1 \n",
      "In shape: 67, Out shape 127**.\n",
      "CASE 1 \n",
      "In shape: 127, Out shape 128**.\n",
      "CASE 2 \n",
      "In shape: 128, Out shape 221.\n",
      "DOWN ka conv\n",
      "CASE 1 \n",
      "In shape: 224, Out shape 43**.\n",
      "CASE 1 \n",
      "In shape: 43, Out shape 109**.\n",
      "CASE 2 \n",
      "In shape: 109, Out shape 144.\n",
      "CASE 1 \n",
      "In shape: 144, Out shape 116**.\n",
      "CASE 1 \n",
      "In shape: 116, Out shape 118**.\n",
      "CASE 2 \n",
      "In shape: 118, Out shape 168.\n",
      "CASE 1 \n",
      "In shape: 168, Out shape 123**.\n",
      "CASE 1 \n",
      "In shape: 123, Out shape 127**.\n",
      "CASE 2 \n",
      "In shape: 127, Out shape 147.\n",
      "CASE 1 \n",
      "In shape: 147, Out shape 256**.\n",
      "CASE 1 \n",
      "In shape: 256, Out shape 255**.\n",
      "CASE 2 \n",
      "In shape: 255, Out shape 569.\n",
      "DOWN ka conv\n",
      "CASE 1 \n",
      "In shape: 299, Out shape 217**.\n",
      "CASE 1 \n",
      "In shape: 217, Out shape 247**.\n",
      "CASE 2 \n",
      "In shape: 247, Out shape 247.\n",
      "CASE 1 \n",
      "In shape: 247, Out shape 216**.\n",
      "CASE 1 \n",
      "In shape: 216, Out shape 247**.\n",
      "CASE 2 \n",
      "In shape: 247, Out shape 181.\n",
      "CASE 1 \n",
      "In shape: 181, Out shape 233**.\n",
      "CASE 1 \n",
      "In shape: 233, Out shape 242**.\n",
      "CASE 2 \n",
      "In shape: 242, Out shape 208.\n",
      "CASE 1 \n",
      "In shape: 208, Out shape 238**.\n",
      "CASE 1 \n",
      "In shape: 238, Out shape 242**.\n",
      "CASE 2 \n",
      "In shape: 242, Out shape 254.\n",
      "CASE 1 \n",
      "In shape: 254, Out shape 251**.\n",
      "CASE 1 \n",
      "In shape: 251, Out shape 254**.\n",
      "CASE 2 \n",
      "In shape: 254, Out shape 329.\n",
      "CASE 1 \n",
      "In shape: 329, Out shape 512**.\n",
      "CASE 1 \n",
      "In shape: 512, Out shape 512**.\n",
      "CASE 2 \n",
      "In shape: 512, Out shape 2048.\n",
      "DOWN ka conv\n",
      "CASE 1 \n",
      "In shape: 2048, Out shape 512**.\n",
      "CASE 1 \n",
      "In shape: 512, Out shape 512**.\n",
      "CASE 2 \n",
      "In shape: 512, Out shape 2048.\n",
      "CASE 1 \n",
      "In shape: 2048, Out shape 512**.\n",
      "CASE 1 \n",
      "In shape: 512, Out shape 512**.\n",
      "CASE 2 \n",
      "In shape: 512, Out shape 2048.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "newmodel = resnet50(cfg=cfg)\n",
    "old_modules = list(model.modules())\n",
    "new_modules = list(newmodel.modules())\n",
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "conv_count = 0\n",
    "\n",
    "for layer_id in range(len(old_modules)):\n",
    "    m0 = old_modules[layer_id]\n",
    "    m1 = new_modules[layer_id]\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        if idx1.size == 1:\n",
    "            idx1 = np.resize(idx1,(1,))\n",
    "\n",
    "        if isinstance(old_modules[layer_id + 1], channel_selection):\n",
    "            # If the next layer is the channel selection layer, then the current batchnorm 2d layer won't be pruned.\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            m1.bias.data = m0.bias.data.clone()\n",
    "            m1.running_mean = m0.running_mean.clone()\n",
    "            m1.running_var = m0.running_var.clone()\n",
    "\n",
    "            # We need to set the channel selection layer.\n",
    "            m2 = new_modules[layer_id + 1]\n",
    "            m2.indexes.data.zero_()\n",
    "            m2.indexes.data[idx1.tolist()] = 1.0\n",
    "\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "        else:\n",
    "            m1.weight.data = m0.weight.data[idx1.tolist()].clone()\n",
    "            m1.bias.data = m0.bias.data[idx1.tolist()].clone()\n",
    "            m1.running_mean = m0.running_mean[idx1.tolist()].clone()\n",
    "            m1.running_var = m0.running_var[idx1.tolist()].clone()\n",
    "            layer_id_in_cfg += 1\n",
    "            start_mask = end_mask.clone()\n",
    "            if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "                end_mask = cfg_mask[layer_id_in_cfg]\n",
    "\n",
    "    \n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        if conv_count == 0:\n",
    "            m1.weight.data = m0.weight.data.clone()\n",
    "            conv_count += 1\n",
    "            print(\"BAHAR ka conv\")\n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+2], nn.Conv2d):\n",
    "            # Residual first case\n",
    "            print(\"CASE 1 \")\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            print('In shape: {:d}, Out shape {:d}**.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            w1 = w1[idx1.tolist(), :, :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "#             if conv_count % 3 != 1:           \n",
    "            continue\n",
    "        if isinstance(old_modules[layer_id+3], nn.ReLU) and isinstance(old_modules[layer_id+2], channel_selection):\n",
    "            # Residualsecond case\n",
    "            print(\"CASE 2 \")\n",
    "            conv_count += 1\n",
    "            idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "            idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "            print('In shape: {:d}, Out shape {:d}.'.format(idx0.size, idx1.size))\n",
    "            if idx0.size == 1:\n",
    "                idx0 = np.resize(idx0, (1,))\n",
    "            if idx1.size == 1:\n",
    "                idx1 = np.resize(idx1, (1,))\n",
    "            w1 = m0.weight.data[:, idx0.tolist(), :, :].clone()\n",
    "            m1.weight.data = w1.clone()\n",
    "            continue\n",
    "        print(\"DOWN ka conv\")\n",
    "        m1.weight.data = m0.weight.data.clone()\n",
    " \n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        if idx0.size == 1:\n",
    "            idx0 = np.resize(idx0, (1,))\n",
    "\n",
    "        m1.weight.data = m0.weight.data[:, idx0].clone()\n",
    "        m1.bias.data = m0.bias.data.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'cfg': cfg, 'state_dict': newmodel.state_dict()},'/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/dimp50_correct.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.load_state_dict(torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/dimp50_correct.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg1 = torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/dimp50_correct.pth.tar')['cfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = resnet50(cfg = cfg1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([62, 3, 7, 7]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([56, 200, 1, 1]) from checkpoint, the shape in current model is torch.Size([200, 133, 1, 1]).\n\tsize mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([60, 56, 3, 3]) from checkpoint, the shape in current model is torch.Size([60, 200, 3, 3]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([43, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([224, 221, 1, 1]).\n\tsize mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([109, 43, 3, 3]) from checkpoint, the shape in current model is torch.Size([109, 224, 3, 3]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([217, 299, 1, 1]) from checkpoint, the shape in current model is torch.Size([299, 569, 1, 1]).\n\tsize mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([247, 217, 3, 3]) from checkpoint, the shape in current model is torch.Size([247, 299, 3, 3]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 3, 3]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ced510450dee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/dimp50_correct.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1071\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([64, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([62, 3, 7, 7]).\n\tsize mismatch for layer1.1.conv1.weight: copying a param with shape torch.Size([56, 200, 1, 1]) from checkpoint, the shape in current model is torch.Size([200, 133, 1, 1]).\n\tsize mismatch for layer1.1.bn1.weight: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.bn1.bias: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.bn1.running_mean: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.bn1.running_var: copying a param with shape torch.Size([56]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for layer1.1.conv2.weight: copying a param with shape torch.Size([60, 56, 3, 3]) from checkpoint, the shape in current model is torch.Size([60, 200, 3, 3]).\n\tsize mismatch for layer2.1.conv1.weight: copying a param with shape torch.Size([43, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([224, 221, 1, 1]).\n\tsize mismatch for layer2.1.bn1.weight: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.bn1.bias: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.bn1.running_mean: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.bn1.running_var: copying a param with shape torch.Size([43]) from checkpoint, the shape in current model is torch.Size([224]).\n\tsize mismatch for layer2.1.conv2.weight: copying a param with shape torch.Size([109, 43, 3, 3]) from checkpoint, the shape in current model is torch.Size([109, 224, 3, 3]).\n\tsize mismatch for layer3.1.conv1.weight: copying a param with shape torch.Size([217, 299, 1, 1]) from checkpoint, the shape in current model is torch.Size([299, 569, 1, 1]).\n\tsize mismatch for layer3.1.bn1.weight: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.bn1.bias: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.bn1.running_mean: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.bn1.running_var: copying a param with shape torch.Size([217]) from checkpoint, the shape in current model is torch.Size([299]).\n\tsize mismatch for layer3.1.conv2.weight: copying a param with shape torch.Size([247, 217, 3, 3]) from checkpoint, the shape in current model is torch.Size([247, 299, 3, 3]).\n\tsize mismatch for layer4.1.conv1.weight: copying a param with shape torch.Size([512, 2048, 1, 1]) from checkpoint, the shape in current model is torch.Size([2048, 2048, 1, 1]).\n\tsize mismatch for layer4.1.bn1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.bn1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for layer4.1.conv2.weight: copying a param with shape torch.Size([512, 512, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 2048, 3, 3])."
     ]
    }
   ],
   "source": [
    "new = resnet50(cfg = cfg1)\n",
    "new.load_state_dict(torch.load('/workspace/tracking_datasets/pruned_ckpts/dimp50_correct/dimp50_correct.pth.tar')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('pruned.pth.tar')['state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['conv1.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv\n",
    "bn\n",
    "\n",
    "layer1\n",
    "    3conv 3bn\n",
    "    X3\n",
    "layer2\n",
    "    3conv 3bn\n",
    "    X4\n",
    "layer3\n",
    "    3conv 3bn\n",
    "    X6\n",
    "layer4\n",
    "    3conv 3bn\n",
    "    X3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
